{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'test', 'train.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "d8c0a35716c8cc97b11227ec6677f491aa307de3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import scipy\n",
    "import cv2\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "bfc901dd07e761741d6f505e468d534b02964bb0"
   },
   "outputs": [],
   "source": [
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "a072507a4b551ae47a0a998dd9290d0c5fc650b1"
   },
   "source": [
    "**Exploration**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "e00ae99faa263f5ab696f56d379fd4e6fe999389"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_data = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "396ccaaa12bddec9f19f8d82d5113a0c36a8532b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "11bb60dee5e37d08d8893070b71d017e57517298"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>has_cactus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000d1e9a533f62e55c289303b072733d.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011485b40695e9138e92d0b3fb55128.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0014d7a11e90b62848904c1418fc8cf2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  has_cactus\n",
       "0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n",
       "1  000c8a36845c0208e833c79c1bffedd1.jpg           1\n",
       "2  000d1e9a533f62e55c289303b072733d.jpg           1\n",
       "3  0011485b40695e9138e92d0b3fb55128.jpg           1\n",
       "4  0014d7a11e90b62848904c1418fc8cf2.jpg           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "6e8365660954efe5c325cfbd9f46623c20921569"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_data.has_cactus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "516f2aad4774dff5de80504089d4bd9e940e08e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fedb9b7a080>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_data.has_cactus.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "0961d59ffd56bffd8e4e092ea42fe0c743a7b405"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13136\n",
       "0     4364\n",
       "Name: has_cactus, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_data.has_cactus.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "e8ac9eba107afe5c2d99b7b2da52ef2d57449da7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fedb9aa7f98>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_data.has_cactus.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8b71d697d0f8911bc5aa51a10494319ed7544560"
   },
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "f9ff1b40ee8496610a4cb47eeb5da6a02a422b7e"
   },
   "outputs": [],
   "source": [
    "\n",
    "def image_generator2(batch_size = 16, all_data=True, shuffle=True, train=True, indexes=None):\n",
    "    while True:\n",
    "        if indexes is None:\n",
    "            if train:\n",
    "                if all_data:\n",
    "                    indexes = np.arange(train_data.shape[0])\n",
    "                else:\n",
    "                    indexes = np.arange(train_data[:15000].shape[0])\n",
    "                if shuffle:\n",
    "                    np.random.shuffle(indexes)\n",
    "            else:\n",
    "                indexes = np.arange(train_data[15000:].shape[0])\n",
    "            \n",
    "        N = int(len(indexes) / batch_size)\n",
    "       \n",
    "\n",
    "        # Read in each input, perform preprocessing and get labels\n",
    "        for i in range(N):\n",
    "            current_indexes = indexes[i*batch_size: (i+1)*batch_size]\n",
    "            batch_input = []\n",
    "            batch_output = [] \n",
    "            for index in current_indexes:\n",
    "                img = mpimg.imread('../input/train/train/' + train_data.id[index])\n",
    "                batch_input += [img]\n",
    "                batch_input += [img[::-1, :, :]]\n",
    "                batch_input += [img[:, ::-1, :]]\n",
    "                batch_input += [np.rot90(img)]\n",
    "                \n",
    "                temp_img = np.zeros_like(img)\n",
    "                temp_img[:28, :, :] = img[4:, :, :]\n",
    "                batch_input += [temp_img]\n",
    "                \n",
    "                temp_img = np.zeros_like(img)\n",
    "                temp_img[:, :28, :] = img[:, 4:, :]\n",
    "                batch_input += [temp_img]\n",
    "                \n",
    "                temp_img = np.zeros_like(img)\n",
    "                temp_img[4:, :, :] = img[:28, :, :]\n",
    "                batch_input += [temp_img]\n",
    "                \n",
    "                temp_img = np.zeros_like(img)\n",
    "                temp_img[:, 4:, :] = img[:, :28, :]\n",
    "                batch_input += [temp_img]\n",
    "                \n",
    "                batch_input += [cv2.resize(img[2:30, 2:30, :], (32, 32))]\n",
    "                \n",
    "                batch_input += [scipy.ndimage.interpolation.rotate(img, 10, reshape=False)]\n",
    "                \n",
    "                batch_input += [scipy.ndimage.interpolation.rotate(img, 5, reshape=False)]\n",
    "                \n",
    "                \n",
    "                for _ in range(11):\n",
    "                    batch_output += [train_data.has_cactus[index]]\n",
    "                \n",
    "            batch_input = np.array( batch_input )\n",
    "            batch_output = np.array( batch_output )\n",
    "        \n",
    "            yield( batch_input, batch_output.reshape(-1, 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_examples = train_data[train_data.has_cactus==1]\n",
    "negative_examples = train_data[train_data.has_cactus==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_img(img):\n",
    "    batch_input = []\n",
    "    batch_input += [img]\n",
    "    batch_input += [img[::-1, :, :]]\n",
    "    batch_input += [img[:, ::-1, :]]\n",
    "    batch_input += [np.rot90(img)]\n",
    "                \n",
    "    temp_img = np.zeros_like(img)\n",
    "    temp_img[:28, :, :] = img[4:, :, :]\n",
    "    batch_input += [temp_img]\n",
    "                \n",
    "    temp_img = np.zeros_like(img)\n",
    "    temp_img[:, :28, :] = img[:, 4:, :]\n",
    "    batch_input += [temp_img]\n",
    "                \n",
    "    temp_img = np.zeros_like(img)\n",
    "    temp_img[4:, :, :] = img[:28, :, :]\n",
    "    batch_input += [temp_img]\n",
    "                \n",
    "    temp_img = np.zeros_like(img)\n",
    "    temp_img[:, 4:, :] = img[:, :28, :]\n",
    "    batch_input += [temp_img]\n",
    "                \n",
    "    batch_input += [cv2.resize(img[2:30, 2:30, :], (32, 32))]\n",
    "                \n",
    "    batch_input += [scipy.ndimage.interpolation.rotate(img, 10, reshape=False)]\n",
    "                \n",
    "    batch_input += [scipy.ndimage.interpolation.rotate(img, 5, reshape=False)]\n",
    "    \n",
    "    return batch_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "b3c9f90999806f09488b0c86dba480784dd024eb"
   },
   "outputs": [],
   "source": [
    "\n",
    "def image_generator(batch_size = 8, all_data=True, shuffle=True, train=True, indexes=None):\n",
    "    while True:\n",
    "        if indexes is None:\n",
    "            if train:\n",
    "                indexes = positive_examples.index.tolist()\n",
    "                neg_indexes = negative_examples.index.tolist()\n",
    "                if shuffle:\n",
    "                    np.random.shuffle(indexes)\n",
    "                    np.random.shuffle(neg_indexes)\n",
    "            \n",
    "        N = int(len(indexes) / (batch_size/2))\n",
    "        neg_N = int(len(neg_indexes) / (batch_size/2))\n",
    "       \n",
    "        j = 0\n",
    "\n",
    "        # Read in each input, perform preprocessing and get labels\n",
    "        for i in range(N):\n",
    "            current_indexes = indexes[i*(batch_size//2): (i+1)*(batch_size//2)]\n",
    "            current_neg_indexes = neg_indexes[j*(batch_size//2): (j+1)*(batch_size//2)]\n",
    "            j = (j + 1) % neg_N\n",
    "            batch_input = []\n",
    "            batch_output = [] \n",
    "            for ind in range(len(current_indexes)):\n",
    "                index = current_indexes[ind]\n",
    "                neg_index = current_neg_indexes[ind]\n",
    "                \n",
    "                img = mpimg.imread('../input/train/train/' + train_data.id[index])\n",
    "                batch_input.extend(augment_img(img))\n",
    "                for _ in range(11):\n",
    "                    batch_output += [train_data.has_cactus[index]]\n",
    "                \n",
    "                neg_img = mpimg.imread('../input/train/train/' + train_data.id[neg_index])\n",
    "                batch_input.extend(augment_img(neg_img))\n",
    "                for _ in range(11):\n",
    "                    batch_output += [train_data.has_cactus[neg_index]]\n",
    "                \n",
    "#                 factor = 0.05\n",
    "#                 new_img = factor*neg_img + (1-factor)*img\n",
    "#                 batch_input.append(new_img)\n",
    "#                 batch_output += [factor*train_data.has_cactus[neg_index]+(1-factor)*train_data.has_cactus[index]]\n",
    "                \n",
    "#                 factor = 0.95\n",
    "#                 new_img = factor*neg_img + (1-factor)*img\n",
    "#                 batch_input.append(new_img)\n",
    "#                 batch_output += [factor*train_data.has_cactus[neg_index]+(1-factor)*train_data.has_cactus[index]]\n",
    "            \n",
    "                \n",
    "                \n",
    "            batch_input = np.array( batch_input )\n",
    "            batch_output = np.array( batch_output )\n",
    "        \n",
    "            yield( batch_input, batch_output.reshape(-1, 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "4337c52c9073b3386d503202392af4a6f7fb4dc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(64, (5, 5), input_shape=(32, 32, 3)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (5, 5)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (5, 5)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (5, 5)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "\n",
    "model.add(keras.layers.Conv2D(256, (3, 3)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "\n",
    "model.add(keras.layers.Conv2D(256, (3, 3)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "\n",
    "model.add(keras.layers.Conv2D(512, (3, 3)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(keras.layers.Dense(100))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "94139886cb2ac2e3d09ca4a439a02a5a7c60017c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 10, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5120100   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 7,913,625\n",
      "Trainable params: 7,910,609\n",
      "Non-trainable params: 3,016\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "b49b1fbb16775b030237fe721d9ed550242cb56e"
   },
   "outputs": [],
   "source": [
    "\n",
    "opt = keras.optimizers.SGD(lr=0.0001, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "5ce20c2953167cd775249eb4bcd1f074d1e97ca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "2188/2187 [==============================] - 86s 39ms/step - loss: 0.0982 - acc: 0.9642\n",
      "Epoch 2/30\n",
      "2188/2187 [==============================] - 81s 37ms/step - loss: 0.0414 - acc: 0.9855\n",
      "Epoch 3/30\n",
      "2188/2187 [==============================] - 80s 37ms/step - loss: 0.0200 - acc: 0.9931\n",
      "Epoch 4/30\n",
      "2188/2187 [==============================] - 80s 37ms/step - loss: 0.0122 - acc: 0.9961\n",
      "Epoch 5/30\n",
      "2188/2187 [==============================] - 80s 37ms/step - loss: 0.0066 - acc: 0.9982\n",
      "Epoch 6/30\n",
      "1897/2187 [=========================>....] - ETA: 10s - loss: 0.0050 - acc: 0.9988"
     ]
    }
   ],
   "source": [
    "def step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, step_size=10):\n",
    "    '''\n",
    "    Wrapper function to create a LearningRateScheduler with step decay schedule.\n",
    "    '''\n",
    "    def schedule(epoch):\n",
    "        return initial_lr * (decay_factor ** np.floor(epoch/step_size))\n",
    "    \n",
    "    return keras.callbacks.LearningRateScheduler(schedule)\n",
    "\n",
    "lr_sched = step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, step_size=2)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "model.fit_generator(image_generator(), steps_per_epoch= train_data.shape[0] / 8, epochs=30, callbacks=[lr_sched, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, step_size=10):\n",
    "#     '''\n",
    "#     Wrapper function to create a LearningRateScheduler with step decay schedule.\n",
    "#     '''\n",
    "#     def schedule(epoch):\n",
    "#         return initial_lr * (decay_factor ** np.floor(epoch/step_size))\n",
    "    \n",
    "#     return keras.callbacks.LearningRateScheduler(schedule)\n",
    "\n",
    "# lr_sched = step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, step_size=2)\n",
    "\n",
    "# model.fit_generator(image_generator(), steps_per_epoch= train_data.shape[0] / 8, epochs=20, callbacks=[lr_sched])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.009791018411583233, 0.9962779681069635]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(image_generator2(), steps=train_data.shape[0]//16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate_generator(image_generator(), steps=train_data.shape[0]//8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "d7db07bc211668a4f280a8a127911dc41ad2d5ac"
   },
   "outputs": [],
   "source": [
    "\n",
    "# keras.backend.eval(model.optimizer.lr.assign(0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "c10eb0a90953f8afd803e65b8106d806278eb81f"
   },
   "outputs": [],
   "source": [
    "\n",
    "# model.fit_generator(image_generator(), steps_per_epoch= train_data.shape[0] / 16, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "96dfee3f7779bf3ab414e1641fc6f232bee977f9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "c2a3fec0fad75eba5b16335a8caf4716c63639a9"
   },
   "outputs": [],
   "source": [
    "\n",
    "indexes = np.arange(train_data.shape[0])\n",
    "N = int(len(indexes) / 64)   \n",
    "batch_size = 64\n",
    "\n",
    "wrong_ind = []\n",
    "for i in range(N):\n",
    "            current_indexes = indexes[i*64: (i+1)*64]\n",
    "            batch_input = []\n",
    "            batch_output = [] \n",
    "            for index in current_indexes:\n",
    "                img = mpimg.imread('../input/train/train/' + train_data.id[index])\n",
    "                batch_input += [img]\n",
    "                batch_output.append(train_data.has_cactus[index])\n",
    "            \n",
    "            batch_input = np.array( batch_input )\n",
    "#             batch_output = np.array( batch_output )\n",
    "\n",
    "            model_pred = model.predict_classes(batch_input)\n",
    "            for j in range(len(batch_output)):\n",
    "                if model_pred[j] != batch_output[j]:\n",
    "                    wrong_ind.append(i*batch_size+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "02cbcd07663980d89c0229052040e7a6efc3cea9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(wrong_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "99aba14ddb0268f0b8ff0b1af520a2eb5694a59e"
   },
   "outputs": [],
   "source": [
    "\n",
    "indexes = np.arange(train_data.shape[0])\n",
    "N = int(len(indexes) / 64)   \n",
    "batch_size = 64\n",
    "\n",
    "wrong_ind = []\n",
    "for i in range(N):\n",
    "            current_indexes = indexes[i*64: (i+1)*64]\n",
    "            batch_input = []\n",
    "            batch_output = [] \n",
    "            for index in current_indexes:\n",
    "                img = mpimg.imread('../input/train/train/' + train_data.id[index])\n",
    "                batch_input += [img[::-1, :, :]]\n",
    "                batch_output.append(train_data.has_cactus[index])\n",
    "            \n",
    "            batch_input = np.array( batch_input )\n",
    "\n",
    "            model_pred = model.predict_classes(batch_input)\n",
    "            for j in range(len(batch_output)):\n",
    "                if model_pred[j] != batch_output[j]:\n",
    "                    wrong_ind.append(i*batch_size+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "6f60db58eb1452f2a1efa579cf3553d3ed97b760"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(wrong_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "3f3df1560928f63f709862bd2cf157626c91419f"
   },
   "outputs": [],
   "source": [
    "\n",
    "indexes = np.arange(train_data.shape[0])\n",
    "N = int(len(indexes) / 64)   \n",
    "batch_size = 64\n",
    "\n",
    "wrong_ind = []\n",
    "for i in range(N):\n",
    "            current_indexes = indexes[i*64: (i+1)*64]\n",
    "            batch_input = []\n",
    "            batch_output = [] \n",
    "            for index in current_indexes:\n",
    "                img = mpimg.imread('../input/train/train/' + train_data.id[index])\n",
    "                batch_input += [img[:, ::-1, :]]\n",
    "                batch_output.append(train_data.has_cactus[index])\n",
    "            \n",
    "            batch_input = np.array( batch_input )\n",
    "\n",
    "            model_pred = model.predict_classes(batch_input)\n",
    "            for j in range(len(batch_output)):\n",
    "                if model_pred[j] != batch_output[j]:\n",
    "                    wrong_ind.append(i*batch_size+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "2080af1860ec56cb4995fc9a994a5466d963980b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(wrong_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "8721278a9113d1f31ffbe6bfb2c7e9f50efdd3cc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "19f369e7b978dbbe62cf90798a58fea1f9618421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls ../input/test/test/* | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "0647c120d566e8e610c47a6b0c7ce302453607e2"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_files = os.listdir('../input/test/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "0ec494e58bd9cae89de579c0f139f19758dede6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "5da812ece13b25665dc1c608e5b6aacdcf1611f9"
   },
   "outputs": [],
   "source": [
    "\n",
    "batch = 40\n",
    "all_out = []\n",
    "for i in range(int(4000/batch)):\n",
    "    images = []\n",
    "    for j in range(batch):\n",
    "        img = mpimg.imread('../input/test/test/'+test_files[i*batch + j])\n",
    "        images += [img]\n",
    "    out = model.predict(np.array(images))\n",
    "    all_out += [out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "410fff04d4f646e25bef760bc2a72b45e2c51642"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "230944dcd785fa2c6e3cefeda0798bab12361397"
   },
   "outputs": [],
   "source": [
    "\n",
    "all_out = np.array(all_out).reshape((-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "998937f04a36ee9f575b10b82e7e5783db9ab91a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "b43a6dbc8ddba1234edaf899192273da3936f544"
   },
   "outputs": [],
   "source": [
    "\n",
    "sub_file = pd.DataFrame(data = {'id': test_files, 'has_cactus': all_out.reshape(-1).tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "6122bc9076f7ac65545921713f77b8358a250e15"
   },
   "outputs": [],
   "source": [
    "\n",
    "sub_file.to_csv('sample_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
