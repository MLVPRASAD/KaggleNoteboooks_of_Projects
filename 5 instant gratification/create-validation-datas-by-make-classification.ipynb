{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is aimed to create an useable offline train-test files for validation purpose by using make_classification with appropriate parameters.\n",
    "\n",
    "* 2019-06-20 v16 update, add high-scores publick kernel validation result. The code will release after competition end.\n",
    "* 2019-06-18 v14 update, add comparison of GMM-EM model\n",
    "* 2019-06-17 v13 update, add comparison of PCA+NuSVC model\n",
    "* 2019-06-16 v12 update, fixed some problem\n",
    "* 2019-06-16 v8 update, n_clusters_per_class=2\n",
    "* 2019-06-16 v7 update, check pseudo labeling works or not\n",
    "* 2019-06-15 v6 update, check redundant will make the prediction different or not, results shows that n_redundant probably should be 0\n",
    "\n",
    "As the result, the QDA auc scores (original data V.S. our data that created by make_classification) looks almost the same (dif < 0.0005), the std is nearly equal, and the 25%, 50%, 75% auc score is also very close. So I think it's good to use it to double-check your method is overfitting the LB or not.\n",
    "\n",
    "*(But be aware the parameters are tuned by myself, so you may change the parameter settings to have a more accurate train-test files.)*\n",
    "\n",
    "The following is this kernels outline.\n",
    "\n",
    "+ High-scores publick kernel validation result (new)\n",
    "+ Previous work\n",
    "+ Check the n_informative range\n",
    "+ Create train-test data by ourself\n",
    "+ Use QDA model to check the performance is equal to current CV/Public LB or not\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High-scores publick kernel validation result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  kernel_name     ...      final_rank\n",
      "0                                      flip-y     ...             7.0\n",
      "1                        pl-lasso-gmm-pca-qda     ...             4.0\n",
      "2                               14-06-2019-v3     ...             3.0\n",
      "3              ensemble-oftop-3-public-kernel     ...             1.0\n",
      "4  tune-hyperparameter-and-add-standardscalar     ...             2.0\n",
      "5                   pseudo-labeling-qda-0-969     ...             6.0\n",
      "6              graphicallasso-gaussianmixture     ...             5.0\n",
      "\n",
      "[7 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# source from https://www.kaggle.com/infinitewing/for-fun\n",
    "import pandas as pd; import numpy as np\n",
    "kernel_df = pd.read_csv('../input/for-fun/kernel_df.csv')\n",
    "kernel_df['final_score'] = (kernel_df['kernel_plb_score'] \n",
    "                            + kernel_df['kernel_valid_oof_score']\n",
    "                            + kernel_df['kernel_valid_preds_score']) / 3\n",
    "kernel_df['plb_rank'] = kernel_df['kernel_plb_score'].rank(ascending=False)\n",
    "kernel_df['valid_oof_rank'] = kernel_df['kernel_valid_oof_score'].rank(ascending=False)\n",
    "kernel_df['valid_test_rank'] = kernel_df['kernel_valid_preds_score'].rank(ascending=False)\n",
    "kernel_df['final_rank'] = kernel_df['final_score'].rank(ascending=False)\n",
    "print(kernel_df)\n",
    "kernel_df.to_csv('kernel_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previous work\n",
    "As we known from some past posts, the train-test data are generated by sklearn.datasets.make_classification()\n",
    "Let's see the parameters information from official doc from scikit-learn.\n",
    "\n",
    "> sklearn.datasets.make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)[source]\n",
    "\n",
    "For these parameters, we can know that the overall flip_y would be 0.05, n_informative is between 33 to 47 (see below), n_redundant is 0, n_repeated is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the n_informative range\n",
    "Let's start some data analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train = pd.read_csv('../input/instant-gratification/train.csv')\n",
    "test = pd.read_csv('../input/instant-gratification/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wheezy-copper-turtle-magic has 512 unique values.\n"
     ]
    }
   ],
   "source": [
    "cols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n",
    "magic_turtles = len(train['wheezy-copper-turtle-magic'].unique())\n",
    "print('wheezy-copper-turtle-magic has {} unique values.'.format(magic_turtles))\n",
    "\n",
    "useful_cols_count = np.zeros(magic_turtles)\n",
    "useful_cols_count = useful_cols_count.astype('int32')\n",
    "for i in range(magic_turtles):\n",
    "    train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "    train_data2 = VarianceThreshold(threshold=2).fit_transform(train2[cols])\n",
    "    train2 = train2[cols].values\n",
    "    \n",
    "    useful_cols_count[i] = train_data2.shape[1]\n",
    "    '''\n",
    "    # check if the useful cols in test and train are the same\n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "    test_data2 = VarianceThreshold(threshold=2).fit_transform(test2[cols])\n",
    "    test2 = test2[cols].values\n",
    "    \n",
    "    print(train2.shape[1])\n",
    "    print(train_data2.shape[1])\n",
    "    for _i in range(train_data2.shape[1]):\n",
    "        for _j in range(train2.shape[1]):\n",
    "            if(np.sum(train_data2[:,_i] - train2[:,_j]) == 0):\n",
    "                if(np.sum(test_data2[:,_i] - test2[:,_j]) == 0):\n",
    "                    print('train_data2[:,{}] == train2[:,{}]'.format(_i, _j))\n",
    "                break\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    512.000000\n",
      "mean      39.765625\n",
      "std        4.353705\n",
      "min       33.000000\n",
      "25%       36.000000\n",
      "50%       40.000000\n",
      "75%       43.000000\n",
      "max       47.000000\n",
      "Name: useful_cols_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['wheezy-copper-turtle-magic'] = np.array([i for i in range(magic_turtles)])\n",
    "df['useful_cols_count'] = useful_cols_count\n",
    "#print(df)\n",
    "print(df['useful_cols_count'].describe())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can knows that n_informative is probably between 33 to 47, it's a great start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train-test data by ourself\n",
    "Before we start creat train-test data by ourself, we need to know how many rows need to be create in each subset(i.e. groupby(n_informative))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   wheezy-copper-turtle-magic       ...         total_test_rows\n",
      "0                           0       ...                     253\n",
      "1                           1       ...                     250\n",
      "2                           2       ...                     290\n",
      "3                           3       ...                     241\n",
      "4                           4       ...                     238\n",
      "5                           5       ...                     256\n",
      "6                           6       ...                     277\n",
      "7                           7       ...                     248\n",
      "8                           8       ...                     222\n",
      "9                           9       ...                     249\n",
      "\n",
      "[10 rows x 4 columns]\n",
      "True\n",
      "True\n",
      "total_train_rows    262144\n",
      "total_test_rows     131073\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['total_train_rows'] = [0 for _ in range(magic_turtles)]\n",
    "df['total_test_rows'] = [0 for _ in range(magic_turtles)]\n",
    "for i in range(magic_turtles):\n",
    "    total_train_rows = train[train['wheezy-copper-turtle-magic'] == i]['wheezy-copper-turtle-magic'].count()\n",
    "    total_test_rows = test[test['wheezy-copper-turtle-magic'] == i]['wheezy-copper-turtle-magic'].count()\n",
    "    df.loc[df['wheezy-copper-turtle-magic'] == i, ['total_train_rows']] = total_train_rows\n",
    "    df.loc[df['wheezy-copper-turtle-magic'] == i, ['total_test_rows']] = total_test_rows\n",
    "print(df.head(10))\n",
    "print(df['total_train_rows'].sum() == train.shape[0])\n",
    "print(df['total_test_rows'].sum() == test.shape[0])\n",
    "print(df[['total_train_rows','total_test_rows']].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how many rows need to be create in each subset! Let's start create our offline train-test datas. \n",
    "<font color=\"#a11\">Noted that I test the parameter setting to make the QDA model has the (almost) same cv and test result. (compared to QDA model that use original train-test data). So you may change the parameter setting on you own.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "(262144, 257)\n",
      "(131073, 257)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "train_for_valid = False\n",
    "test_for_valid = False\n",
    "for i, row in df.iterrows():\n",
    "    if(i%50 == 0): print(i)\n",
    "    np.random.seed(520999+i)\n",
    "    useful_cols_count = row['useful_cols_count']\n",
    "    total_train_rows = row['total_train_rows']\n",
    "    total_test_rows = row['total_test_rows']\n",
    "    X, y = make_classification(n_samples=total_train_rows+total_test_rows, n_features=255, \\\n",
    "                               n_informative=useful_cols_count, n_redundant=0, \\\n",
    "                               n_clusters_per_class=3, \\\n",
    "                               random_state=3228+i, shuffle=True,  \\\n",
    "                               flip_y=0.05)\n",
    "    Xy = np.zeros((total_train_rows+total_test_rows, 257))\n",
    "    Xy[:,:-2] = X\n",
    "    Xy[:,-2] = i # represent 'wheezy-copper-turtle-magic'\n",
    "    Xy[:,-1] = y\n",
    "    if(train_for_valid is False):\n",
    "        train_for_valid = Xy[:total_train_rows,:]\n",
    "        test_for_valid = Xy[total_train_rows:,:]\n",
    "    else:\n",
    "        train_for_valid = np.concatenate((train_for_valid, Xy[:total_train_rows,:]))\n",
    "        test_for_valid = np.concatenate((test_for_valid, Xy[total_train_rows:,:]))\n",
    "print(train_for_valid.shape)\n",
    "print(test_for_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   muggy-smalt-axolotl-pembus   ...    target\n",
      "0                   -2.189532   ...         0\n",
      "1                    0.388506   ...         0\n",
      "\n",
      "[2 rows x 257 columns]\n",
      "   muggy-smalt-axolotl-pembus   ...    target\n",
      "0                   -0.612877   ...         0\n",
      "1                    0.871301   ...         1\n",
      "\n",
      "[2 rows x 257 columns]\n"
     ]
    }
   ],
   "source": [
    "train_valid_df = pd.DataFrame(train_for_valid, columns=cols+['wheezy-copper-turtle-magic', 'target'])\n",
    "test_valid_df = pd.DataFrame(test_for_valid, columns=cols+['wheezy-copper-turtle-magic', 'target'])\n",
    "\n",
    "train_valid_df['wheezy-copper-turtle-magic'] = train_valid_df['wheezy-copper-turtle-magic'].astype('int32')\n",
    "train_valid_df['target'] = train_valid_df['target'].astype('int32')\n",
    "test_valid_df['wheezy-copper-turtle-magic'] = test_valid_df['wheezy-copper-turtle-magic'].astype('int32')\n",
    "test_valid_df['target'] = test_valid_df['target'].astype('int32')\n",
    "print(train_valid_df.head(2))\n",
    "print(test_valid_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use QDA model to check the performance is equal to current CV/Public LB or not\n",
    "Now we use QDA model to test is our created data can has almost same result against original data or not. \n",
    "*The QDA model is based on this kernel:\n",
    "https://www.kaggle.com/speedwagon/quadratic-discriminant-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "def qda(train, test):\n",
    "    oof = np.zeros(len(train))\n",
    "    preds = np.zeros(len(test))\n",
    "    aucs = np.zeros(512)\n",
    "    for i in range(512):\n",
    "        #if(i%50 == 0): print(i)\n",
    "        train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "        test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "        idx1 = train2.index; idx2 = test2.index\n",
    "        train2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "        data2 = VarianceThreshold(threshold=2).fit_transform(data[cols])\n",
    "\n",
    "        train3 = data2[:train2.shape[0]]; test3 = data2[train2.shape[0]:]\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=11, random_state=42)\n",
    "        for train_index, test_index in skf.split(train2, train2['target']):\n",
    "\n",
    "            clf = QuadraticDiscriminantAnalysis(0.1)\n",
    "            clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "            oof[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n",
    "            preds[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        aucs[i] = roc_auc_score(train['target'][idx1], oof[idx1])\n",
    "    auc = roc_auc_score(train['target'], oof)\n",
    "    print('QDA AUC: {}'.format(round(auc,5)))\n",
    "    aucs_df = pd.DataFrame(aucs,columns = ['auc'])\n",
    "    print(aucs_df.describe())\n",
    "    return oof, preds\n",
    "def qda_pseudo(train, test):\n",
    "    oof = np.zeros(len(train))\n",
    "    preds = np.zeros(len(test))\n",
    "    aucs = np.zeros(512)\n",
    "\n",
    "    # BUILD 512 SEPARATE MODELS\n",
    "    for k in range(512):\n",
    "        # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "        train2 = train[train['wheezy-copper-turtle-magic']==k] \n",
    "        train2p = train2.copy(); idx1 = train2.index \n",
    "        test2 = test[test['wheezy-copper-turtle-magic']==k]\n",
    "\n",
    "        # ADD PSEUDO LABELED DATA\n",
    "        test2p = test2[ (test2['target']<=0.01) | (test2['target']>=0.99) ].copy()\n",
    "        test2p.loc[ test2p['target']>=0.5, 'target' ] = 1\n",
    "        test2p.loc[ test2p['target']<0.5, 'target' ] = 0 \n",
    "        train2p = pd.concat([train2p,test2p],axis=0)\n",
    "        train2p.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "        sel = VarianceThreshold(threshold=1.5).fit(train2p[cols])     \n",
    "        train3p = sel.transform(train2p[cols])\n",
    "        train3 = sel.transform(train2[cols])\n",
    "        test3 = sel.transform(test2[cols])\n",
    "\n",
    "        # STRATIFIED K FOLD\n",
    "        skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "        for train_index, test_index in skf.split(train3p, train2p['target']):\n",
    "            test_index3 = test_index[ test_index<len(train3) ] # ignore pseudo in oof\n",
    "\n",
    "            # MODEL AND PREDICT WITH QDA\n",
    "            clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n",
    "            clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n",
    "            oof[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n",
    "            preds[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        aucs[k] = roc_auc_score(train['target'][idx1], oof[idx1])\n",
    "        #if k%64==0: print(k)\n",
    "\n",
    "    # PRINT CV AUC\n",
    "    auc = roc_auc_score(train['target'],oof)\n",
    "    print('Pseudo Labeled QDA scores CV =',round(auc,5))\n",
    "    aucs_df = pd.DataFrame(aucs,columns = ['auc'])\n",
    "    print(aucs_df.describe())\n",
    "    return oof, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA AUC: 0.9649\n",
      "              auc\n",
      "count  512.000000\n",
      "mean     0.964484\n",
      "std      0.009814\n",
      "min      0.935952\n",
      "25%      0.957526\n",
      "50%      0.965457\n",
      "75%      0.971527\n",
      "max      0.988370\n",
      "Pseudo Labeled QDA scores CV = 0.97032\n",
      "              auc\n",
      "count  512.000000\n",
      "mean     0.970091\n",
      "std      0.008576\n",
      "min      0.942778\n",
      "25%      0.964455\n",
      "50%      0.970624\n",
      "75%      0.976524\n",
      "max      0.990307\n"
     ]
    }
   ],
   "source": [
    "oof, preds = qda(train, test)\n",
    "test['target'] = preds\n",
    "oof, preds = qda_pseudo(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA AUC: 0.9643\n",
      "              auc\n",
      "count  512.000000\n",
      "mean     0.963980\n",
      "std      0.009816\n",
      "min      0.926237\n",
      "25%      0.957937\n",
      "50%      0.964436\n",
      "75%      0.970698\n",
      "max      0.992659\n",
      "Pseudo Labeled QDA scores CV = 0.96984\n",
      "              auc\n",
      "count  512.000000\n",
      "mean     0.969642\n",
      "std      0.008766\n",
      "min      0.926466\n",
      "25%      0.963903\n",
      "50%      0.970012\n",
      "75%      0.975137\n",
      "max      0.993182\n"
     ]
    }
   ],
   "source": [
    "oof, preds = qda(train_valid_df, test_valid_df)\n",
    "original_target = test_valid_df['target'].values.copy()\n",
    "test_valid_df['target'] = preds\n",
    "oof, preds = qda_pseudo(train_valid_df, test_valid_df)\n",
    "test_valid_df['target'] = original_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.96899\n"
     ]
    }
   ],
   "source": [
    "# The original LB score is 0.9659\n",
    "auc = roc_auc_score(test_valid_df['target'], preds)\n",
    "print('AUC: {}'.format(round(auc,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the auc scores looks almost the same (dif < 0.0005), the std is nearly equal, and the 25%, 50%, 75% auc score is also very close. \n",
    "Let's test some more popular model before we save file to local.\n",
    "#### PolynomialFeatures + LogisticRegression\n",
    "*Code from: https://www.kaggle.com/gogo827jz/pseudo-labelled-polylr-and-qda*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def log(train, test):\n",
    "    oof = np.zeros(len(train))\n",
    "    preds = np.zeros(len(test))\n",
    "    aucs = np.zeros(512)\n",
    "    for i in range(512):\n",
    "        train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "        test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "        idx1 = train2.index; idx2 = test2.index\n",
    "        train2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Adding quadratic polynomial features can help linear model such as Logistic Regression learn better\n",
    "        poly = PolynomialFeatures(degree=2)\n",
    "        sc = StandardScaler()\n",
    "        data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "        data2 = poly.fit_transform(sc.fit_transform(VarianceThreshold(threshold=2).fit_transform(data[cols])))\n",
    "        train3 = data2[:train2.shape[0]]; test3 = data2[train2.shape[0]:]\n",
    "\n",
    "        # STRATIFIED K FOLD\n",
    "        skf = StratifiedKFold(n_splits=11, random_state=42)\n",
    "        for train_index, test_index in skf.split(train2, train2['target']):\n",
    "\n",
    "            clf = LogisticRegression(solver='liblinear',penalty='l2',C=0.001,tol=0.0001,random_state=0,max_iter=1000,n_jobs=-1)\n",
    "            clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "            oof[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n",
    "            preds[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        aucs[i] = roc_auc_score(train['target'][idx1], oof[idx1])\n",
    "    auc = roc_auc_score(train['target'], oof)\n",
    "    print('LOG AUC: {}'.format(round(auc,5)))\n",
    "    aucs_df = pd.DataFrame(aucs,columns = ['auc'])\n",
    "    print(aucs_df.describe())\n",
    "    return oof, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG AUC: 0.95267\n",
      "              auc\n",
      "count  512.000000\n",
      "mean     0.952816\n",
      "std      0.011561\n",
      "min      0.915342\n",
      "25%      0.945865\n",
      "50%      0.954140\n",
      "75%      0.960486\n",
      "max      0.982128\n",
      "LOG AUC: 0.95174\n",
      "              auc\n",
      "count  512.000000\n",
      "mean     0.951770\n",
      "std      0.011627\n",
      "min      0.915513\n",
      "25%      0.943832\n",
      "50%      0.952318\n",
      "75%      0.959977\n",
      "max      0.987619\n",
      "AUC: 0.9538\n"
     ]
    }
   ],
   "source": [
    "oof, preds = log(train, test)\n",
    "oof, preds = log(train_valid_df, test_valid_df)\n",
    "\n",
    "auc = roc_auc_score(test_valid_df['target'], preds)\n",
    "print('AUC: {}'.format(round(auc,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA + NuSVC\n",
    "*Code from: https://www.kaggle.com/tunguz/pca-nusvc-knn/code*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, neighbors, linear_model, neural_network\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def nusvc(train, test):\n",
    "    oof = np.zeros(len(train))\n",
    "    preds = np.zeros(len(test))\n",
    "    aucs = np.zeros(512)\n",
    "    cols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n",
    "\n",
    "    for i in range(512):\n",
    "        train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "        test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "        idx1 = train2.index; idx2 = test2.index\n",
    "        train2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "        data2 = StandardScaler().fit_transform(PCA(n_components=40, random_state=4).fit_transform(data[cols]))\n",
    "        train3 = data2[:train2.shape[0]]; test3 = data2[train2.shape[0]:]\n",
    "\n",
    "        # STRATIFIED K FOLD (Using splits=25 scores 0.002 better but is slower)\n",
    "        skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "        for train_index, test_index in skf.split(train2, train2['target']):\n",
    "\n",
    "            clf = NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.59, coef0=0.053)\n",
    "            clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "            oof[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n",
    "            preds[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        aucs[i] = roc_auc_score(train['target'][idx1], oof[idx1])\n",
    "    auc = roc_auc_score(train['target'], oof)\n",
    "    print('NUSVC AUC: {}'.format(round(auc,5)))\n",
    "    aucs_df = pd.DataFrame(aucs,columns = ['auc'])\n",
    "    print(aucs_df.describe())\n",
    "    return oof, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUSVC AUC: 0.95513\n",
      "              auc\n",
      "count  512.000000\n",
      "mean     0.954509\n",
      "std      0.012197\n",
      "min      0.907800\n",
      "25%      0.946842\n",
      "50%      0.955963\n",
      "75%      0.963569\n",
      "max      0.984113\n",
      "NUSVC AUC: 0.95401\n",
      "              auc\n",
      "count  512.000000\n",
      "mean     0.953328\n",
      "std      0.012923\n",
      "min      0.903322\n",
      "25%      0.945523\n",
      "50%      0.954056\n",
      "75%      0.962147\n",
      "max      0.990976\n",
      "AUC: 0.96154\n"
     ]
    }
   ],
   "source": [
    "oof, preds = nusvc(train, test)\n",
    "oof, preds = nusvc(train_valid_df, test_valid_df)\n",
    "\n",
    "auc = roc_auc_score(test_valid_df['target'], preds)\n",
    "print('AUC: {}'.format(round(auc,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GMM\n",
    "*Code from: https://www.kaggle.com/christofhenkel/graphicallasso-gaussianmixture*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from sklearn.covariance import GraphicalLasso\n",
    "from sklearn.mixture import GaussianMixture\n",
    "def get_mean_cov(x,y):\n",
    "    model = GraphicalLasso()\n",
    "    ones = (y==1).astype(bool)\n",
    "    x2 = x[ones]\n",
    "    model.fit(x2)\n",
    "    p1 = model.precision_\n",
    "    m1 = model.location_\n",
    "    \n",
    "    onesb = (y==0).astype(bool)\n",
    "    x2b = x[onesb]\n",
    "    model.fit(x2b)\n",
    "    p2 = model.precision_\n",
    "    m2 = model.location_\n",
    "    \n",
    "    ms = np.stack([m1,m2])\n",
    "    ps = np.stack([p1,p2])\n",
    "    return ms,ps\n",
    "\n",
    "def gmm(train, test):\n",
    "    oof = np.zeros(len(train))\n",
    "    preds = np.zeros(len(test))\n",
    "    aucs = np.zeros(512)\n",
    "    cols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n",
    "    # BUILD 512 SEPARATE MODELS\n",
    "    for i in (range(512)):\n",
    "        # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "        train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "        test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "        idx1 = train2.index; idx2 = test2.index\n",
    "        train2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "        sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n",
    "        train3 = sel.transform(train2[cols])\n",
    "        test3 = sel.transform(test2[cols])\n",
    "\n",
    "        # STRATIFIED K-FOLD\n",
    "        skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "        for train_index, test_index in skf.split(train3, train2['target']):\n",
    "\n",
    "            # MODEL AND PREDICT WITH QDA\n",
    "            ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values)\n",
    "            gm = GaussianMixture(n_components=2, init_params='random', covariance_type='full', tol=0.001,reg_covar=0.001, max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n",
    "            gm.fit(np.concatenate([train3[train_index,:],test3],axis = 0))\n",
    "            oof[idx1[test_index]] = gm.predict_proba(train3[test_index,:])[:,0]\n",
    "            preds[idx2] += gm.predict_proba(test3)[:,0] / skf.n_splits\n",
    "        aucs[i] = roc_auc_score(train['target'][idx1], oof[idx1])\n",
    "    auc = roc_auc_score(train['target'], oof)\n",
    "    print('GMM AUC: {}'.format(round(auc,5)))\n",
    "    aucs_df = pd.DataFrame(aucs,columns = ['auc'])\n",
    "    print(aucs_df.describe())\n",
    "    return oof, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM AUC: 0.96878\n",
      "              auc\n",
      "count  512.000000\n",
      "mean     0.968662\n",
      "std      0.008813\n",
      "min      0.940312\n",
      "25%      0.963263\n",
      "50%      0.969029\n",
      "75%      0.975105\n",
      "max      0.990997\n",
      "GMM AUC: 0.96838\n",
      "              auc\n",
      "count  512.000000\n",
      "mean     0.968339\n",
      "std      0.009666\n",
      "min      0.882411\n",
      "25%      0.963114\n",
      "50%      0.968739\n",
      "75%      0.974453\n",
      "max      0.992049\n",
      "AUC: 0.96893\n"
     ]
    }
   ],
   "source": [
    "oof, preds = gmm(train, test)\n",
    "oof, preds = gmm(train_valid_df, test_valid_df)\n",
    "\n",
    "auc = roc_auc_score(test_valid_df['target'], preds)\n",
    "print('AUC: {}'.format(round(auc,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_df.to_csv('train_valid_df.csv', index=False)\n",
    "test_valid_df.to_csv('test_valid_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test our model/algorithm with the file we create!\n",
    "Wish you can find some insights or idea from this kernel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
