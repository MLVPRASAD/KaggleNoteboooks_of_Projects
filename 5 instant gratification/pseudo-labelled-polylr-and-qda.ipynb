{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo-Labelled PolyLR and QDA \n",
    "\n",
    "This kernel shows the potential of adding quadratic polynomial features, a simple logistic regression can learn just like QDA. I also tested pseudo labelling and blending with QDA.\n",
    "\n",
    "Thanks to Chris's great kernels [LR][1], [SVC][2], [probing][3], [pseudo labelling][5] and mhviraf's kernel [make_classification][4] which shows how the dataset was generated. Please also upvote those kernels.\n",
    "\n",
    "[1]: https://www.kaggle.com/cdeotte/logistic-regression-0-800\n",
    "[2]: https://www.kaggle.com/cdeotte/support-vector-machine-0-925\n",
    "[3]: https://www.kaggle.com/cdeotte/private-lb-probing-0-950\n",
    "[4]: https://www.kaggle.com/mhviraf/synthetic-data-for-next-instant-gratification\n",
    "[5]: https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Train\n",
      "Loading Test\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "print('Loading Train')\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "print('Loading Test')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "print('Finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PolyLR and QDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 LR oof auc :  0.93929\n",
      "0 QDA oof auc :  0.95892\n",
      "64 LR oof auc :  0.9795\n",
      "64 QDA oof auc :  0.9825\n",
      "128 LR oof auc :  0.96189\n",
      "128 QDA oof auc :  0.96862\n",
      "192 LR oof auc :  0.97155\n",
      "192 QDA oof auc :  0.97537\n",
      "256 LR oof auc :  0.97274\n",
      "256 QDA oof auc :  0.98375\n",
      "320 LR oof auc :  0.93534\n",
      "320 QDA oof auc :  0.9495\n",
      "384 LR oof auc :  0.94877\n",
      "384 QDA oof auc :  0.96474\n",
      "448 LR oof auc :  0.95906\n",
      "448 QDA oof auc :  0.97544\n"
     ]
    }
   ],
   "source": [
    "oof = np.zeros(len(train))\n",
    "preds = np.zeros(len(test))\n",
    "\n",
    "oof_QDA = np.zeros(len(train))\n",
    "preds_QDA = np.zeros(len(test))\n",
    "\n",
    "cols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n",
    "\n",
    "for i in range(512):\n",
    "    train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "    idx1 = train2.index; idx2 = test2.index\n",
    "    train2.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    # Adding quadratic polynomial features can help linear model such as Logistic Regression learn better\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    sc = StandardScaler()\n",
    "    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "    data2 = sc.fit_transform(poly.fit_transform(VarianceThreshold(threshold=1.5).fit_transform(data[cols])))\n",
    "    train3 = data2[:train2.shape[0]]; test3 = data2[train2.shape[0]:]\n",
    "    \n",
    "    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "    data2 = VarianceThreshold(threshold=1.5).fit_transform(data[cols])\n",
    "    train4 = data2[:train2.shape[0]]; test4 = data2[train2.shape[0]:]\n",
    "    \n",
    "    # STRATIFIED K FOLD\n",
    "    skf = StratifiedKFold(n_splits=11, random_state=42)\n",
    "    for train_index, test_index in skf.split(train2, train2['target']):\n",
    "\n",
    "        clf = LogisticRegression(solver='saga',penalty='l2',C=0.01,tol=0.001)\n",
    "        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n",
    "        preds[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        \n",
    "        clf_QDA = QuadraticDiscriminantAnalysis(reg_param=0.5)\n",
    "        clf_QDA.fit(train4[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_QDA[idx1[test_index]] = clf_QDA.predict_proba(train4[test_index,:])[:,1]\n",
    "        preds_QDA[idx2] += clf_QDA.predict_proba(test4)[:,1] / skf.n_splits\n",
    "        \n",
    "    if i%64==0:\n",
    "        print(i, 'LR oof auc : ', round(roc_auc_score(train['target'][idx1], oof[idx1]), 5))\n",
    "        print(i, 'QDA oof auc : ', round(roc_auc_score(train['target'][idx1], oof_QDA[idx1]), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PolyLR with Pseudo Labelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 LR2 oof auc :  0.94081\n",
      "64 LR2 oof auc :  0.97419\n",
      "128 LR2 oof auc :  0.95845\n",
      "192 LR2 oof auc :  0.97315\n",
      "256 LR2 oof auc :  0.9767\n",
      "320 LR2 oof auc :  0.94159\n",
      "384 LR2 oof auc :  0.9507\n",
      "448 LR2 oof auc :  0.95827\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE VARIABLES\n",
    "test['target'] = preds\n",
    "oof = np.zeros(len(train))\n",
    "preds = np.zeros(len(test))\n",
    "\n",
    "# BUILD 512 SEPARATE MODELS\n",
    "for k in range(512):\n",
    "    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "    train2 = train[train['wheezy-copper-turtle-magic']==k] \n",
    "    train2p = train2.copy(); idx1 = train2.index \n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==k]\n",
    "    \n",
    "    # ADD PSEUDO LABELED DATA\n",
    "    test2p = test2[ (test2['target']<=0.01) | (test2['target']>=0.99) ].copy()\n",
    "    test2p.loc[ test2p['target']>=0.5, 'target' ] = 1\n",
    "    test2p.loc[ test2p['target']<0.5, 'target' ] = 0 \n",
    "    train2p = pd.concat([train2p,test2p],axis=0)\n",
    "    train2p.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "     # FEATURE SELECTION AND ADDING POLYNOMIAL FEATURES\n",
    "    sel = VarianceThreshold(threshold=1.5).fit(train2p[cols])     \n",
    "    train3p = sel.transform(train2p[cols])\n",
    "    train3 = sel.transform(train2[cols])\n",
    "    test3 = sel.transform(test2[cols])   \n",
    "    poly = PolynomialFeatures(degree=2).fit(train3p)\n",
    "    train3p = poly.transform(train3p)\n",
    "    train3 = poly.transform(train3)\n",
    "    test3 = poly.transform(test3)\n",
    "    sc2 = StandardScaler()\n",
    "    train3p = sc2.fit_transform(train3p)\n",
    "    train3 = sc2.transform(train3)\n",
    "    test3 = sc2.transform(test3)\n",
    "        \n",
    "    # STRATIFIED K FOLD\n",
    "    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "    for train_index, test_index in skf.split(train3p, train2p['target']):\n",
    "        test_index3 = test_index[ test_index<len(train3) ] # ignore pseudo in oof\n",
    "        \n",
    "        # MODEL AND PREDICT WITH LR\n",
    "        clf = LogisticRegression(solver='saga',penalty='l2',C=0.01,tol=0.001)\n",
    "        clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n",
    "        oof[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n",
    "        preds[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        \n",
    "    if k%64==0:  \n",
    "        print(k, 'LR2 oof auc : ', round(roc_auc_score(train['target'][idx1], oof[idx1]), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QDA with Pseudo Labelling (Chris's)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 QDA2 oof auc :  0.9649\n",
      "64 QDA2 oof auc :  0.98316\n",
      "128 QDA2 oof auc :  0.97303\n",
      "192 QDA2 oof auc :  0.98157\n",
      "256 QDA2 oof auc :  0.98377\n",
      "320 QDA2 oof auc :  0.95395\n",
      "384 QDA2 oof auc :  0.96582\n",
      "448 QDA2 oof auc :  0.97836\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE VARIABLES\n",
    "test['target'] = preds_QDA\n",
    "oof_QDA2 = np.zeros(len(train))\n",
    "preds_QDA2 = np.zeros(len(test))\n",
    "\n",
    "# BUILD 512 SEPARATE MODELS\n",
    "for k in range(512):\n",
    "    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "    train2 = train[train['wheezy-copper-turtle-magic']==k] \n",
    "    train2p = train2.copy(); idx1 = train2.index \n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==k]\n",
    "    \n",
    "    # ADD PSEUDO LABELED DATA\n",
    "    test2p = test2[ (test2['target']<=0.01) | (test2['target']>=0.99) ].copy()\n",
    "    test2p.loc[ test2p['target']>=0.5, 'target' ] = 1\n",
    "    test2p.loc[ test2p['target']<0.5, 'target' ] = 0 \n",
    "    train2p = pd.concat([train2p,test2p],axis=0)\n",
    "    train2p.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "    sel = VarianceThreshold(threshold=1.5).fit(train2p[cols])     \n",
    "    train3p = sel.transform(train2p[cols])\n",
    "    train3 = sel.transform(train2[cols])\n",
    "    test3 = sel.transform(test2[cols])\n",
    "        \n",
    "    # STRATIFIED K FOLD\n",
    "    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "    for train_index, test_index in skf.split(train3p, train2p['target']):\n",
    "        test_index3 = test_index[ test_index<len(train3) ] # ignore pseudo in oof\n",
    "        \n",
    "        # MODEL AND PREDICT WITH QDA\n",
    "        clf_QDA2 = QuadraticDiscriminantAnalysis(reg_param=0.5)\n",
    "        clf_QDA2.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n",
    "        oof_QDA2[idx1[test_index3]] = clf_QDA2.predict_proba(train3[test_index3,:])[:,1]\n",
    "        preds_QDA2[test2.index] += clf_QDA2.predict_proba(test3)[:,1] / skf.n_splits\n",
    "       \n",
    "    if k%64==0:\n",
    "        print(k, 'QDA2 oof auc : ', round(roc_auc_score(train['target'][idx1], oof_QDA2[idx1]), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR auc:  0.95033\n",
      "QDA auc:  0.97033\n"
     ]
    }
   ],
   "source": [
    "print('LR auc: ', round(roc_auc_score(train['target'], oof),5))\n",
    "print('QDA auc: ', round(roc_auc_score(train['target'], oof_QDA2),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the Best Weights**\n",
    "\n",
    "Let's see if Pseudo-Labelled PolyLR can increase the performance (if w_best > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best weight:  0\n",
      "auc_best:  0.97033\n"
     ]
    }
   ],
   "source": [
    "w_best = 0\n",
    "oof_best = oof_QDA2\n",
    "for w in np.arange(0,0.55,0.001):\n",
    "    oof_blend = w*oof+(1-w)*oof_QDA2\n",
    "    if (roc_auc_score(train['target'], oof_blend)) > (roc_auc_score(train['target'], oof_best)):\n",
    "        w_best = w\n",
    "        oof_best = oof_blend\n",
    "        print(w_best)\n",
    "print('best weight: ', w_best)\n",
    "print('auc_best: ', round(roc_auc_score(train['target'], oof_best), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Blending with the Best Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1c13f2701648e0b0d46d8a2a5a131a53</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ba88c155ba898fc8b5099893036ef205</td>\n",
       "      <td>9.998865e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7cbab5cea99169139e7e6d8ff74ebb77</td>\n",
       "      <td>5.397401e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ca820ad57809f62eb7b4d13f5d4371a0</td>\n",
       "      <td>1.114499e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7baaf361537fbd8a1aaa2c97a6d4ccc7</td>\n",
       "      <td>1.237183e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id        target\n",
       "0  1c13f2701648e0b0d46d8a2a5a131a53  1.000000e+00\n",
       "1  ba88c155ba898fc8b5099893036ef205  9.998865e-01\n",
       "2  7cbab5cea99169139e7e6d8ff74ebb77  5.397401e-13\n",
       "3  ca820ad57809f62eb7b4d13f5d4371a0  1.114499e-03\n",
       "4  7baaf361537fbd8a1aaa2c97a6d4ccc7  1.237183e-03"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "sub['target'] = w_best*preds + (1-w_best)*preds_QDA2\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this kernel, I have tested PolyLR with pseudo labelling and blending with QDA. The results show that PolyLR does not increase the prediction performance of QDA since it has a very similar decision boundary to QDA, as illustrated by Chris in [Examples of Top 6 Classifiers][1].\n",
    "\n",
    "[1]: https://www.kaggle.com/c/instant-gratification/discussion/94179"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
