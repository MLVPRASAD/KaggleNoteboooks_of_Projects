{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "82418877-8407-45ef-9b76-86ca80e07abf",
    "_execution_state": "idle",
    "_uuid": "483f57b296f8d69647bbec1154acfa2da3c6fc2f"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “Hello World” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
    "\n",
    "In this competition, we aim to correctly identify digits from a dataset of tens of thousands of handwritten images. Kaggle has curated a set of tutorial-style kernels which cover everything from regression to neural networks. They hope to encourage us to experiment with different algorithms to learn first-hand what works well and how techniques compare.\n",
    "\n",
    "## Approach\n",
    "\n",
    "For this competition, we will be using Keras (with TensorFlow as our backend) as the main package to create a simple neural network to predict, as accurately as we can, digits from handwritten images. In particular, we will be calling the Functional Model API of Keras, and creating a 4-layered and 5-layered neural network.\n",
    "\n",
    "Also, we will be experimenting with various optimizers: the plain vanilla Stochastic Gradient Descent optimizer and the Adam optimizer. However, there are many other parameters, such as training epochs which will we will not be experimenting with.\n",
    "\n",
    "In addition, the choice of hidden layer units are completely arbitrary and may not be optimal. This is yet another parameter which we will not attempt to tinker with. Lastly, we introduce dropout, a form of regularisation, in our neural networks to prevent overfitting.\n",
    "\n",
    "## Result\n",
    "\n",
    "Following our simulations on the cross validation dataset, it appears that a 4-layered neural network, using 'Adam' as the optimizer along with a learning rate of 0.01, performs best. We proceed to introduce dropout in the model, and use the model to predict for the test set.\n",
    "\n",
    "The test predictions (submitted to Kaggle) generated by our model predicts with an accuracy score of 97.600%, which places us at the top 55 percentile of the competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "440129fa-bb2d-47b8-9415-714467d98743",
    "_execution_state": "idle",
    "_uuid": "44f63ca7fc70094c75598c27b433b316ea406237"
   },
   "source": [
    "Importing key libraries, and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "55ec59e1-8a8c-42d2-8ccc-b6d95ea198b4",
    "_execution_state": "busy",
    "_uuid": "a6d625ede9e19ac1f146a5f63d6ca19c4b98e20c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1212)\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "daa0805e-e1dd-4806-b2db-ff0124febe7d",
    "_execution_state": "busy",
    "_uuid": "be0a7acbb3bfc83fd3103b4a401337aafe57c00d"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "dfae6a31-23ea-4d88-9fcd-06b8b705b614",
    "_execution_state": "busy",
    "_uuid": "0f7bfb5923e5b4ed5a5149c007a2cd39cb9b8282"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head() # 784 features, 1 label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "45bd232a-4000-4a06-a3ed-0be9f993746c",
    "_execution_state": "idle",
    "_uuid": "f0970dcbc0b6791dc44936d8d63e6985dfb6960c"
   },
   "source": [
    "## Splitting into training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "bb78680a-ce50-4ee9-a77f-265b9ee38aee",
    "_execution_state": "busy",
    "_uuid": "16e39b5512ed29c8f9d7db51331693e4689ce306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "df_features = df_train.iloc[:, 1:785]\n",
    "df_label = df_train.iloc[:, 0]\n",
    "\n",
    "X_test = df_test.iloc[:, 0:784]\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "a3fb0b37-1edf-42bd-b951-86f254b78fc1",
    "_execution_state": "busy",
    "_uuid": "a98808f6188e9c44741ad2b5c25a894106406dfc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(df_features, df_label, \n",
    "                                                test_size = 0.2,\n",
    "                                                random_state = 1212)\n",
    "\n",
    "X_train = X_train.as_matrix().reshape(33600, 784) #(33600, 784)\n",
    "X_cv = X_cv.as_matrix().reshape(8400, 784) #(8400, 784)\n",
    "\n",
    "X_test = X_test.as_matrix().reshape(28000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4486ba9e-b8b3-4f09-a597-3d5e6bbd6c1c",
    "_execution_state": "idle",
    "_uuid": "9a10a6e1aae9645a7c3e5a703d78d9c3b096f6d3"
   },
   "source": [
    "## Data cleaning, normalization and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "4d0e07b5-28dd-42f1-b425-6414aea90cde",
    "_execution_state": "busy",
    "_uuid": "cc2daf9f099fb62e3b470f913349428ef396b75b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 255)\n"
     ]
    }
   ],
   "source": [
    "print((min(X_train[1]), max(X_train[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "60b333cc-a76e-4713-97f5-a9095e27e43b",
    "_execution_state": "idle",
    "_uuid": "11d4f22158c013b3f028f5c11340b4a4b7291d1e"
   },
   "source": [
    "As the pixel intensities are currently between the range of 0 and 255, we proceed to normalize the features, using broadcasting. In addition, we proceed to convert our labels from a class vector to binary One Hot Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "e9f8eaa0-c77e-4510-9ff1-bb56e1d5f76d",
    "_execution_state": "busy",
    "_uuid": "c24261ffd2384078a836a909ea4839a31d51dd66"
   },
   "outputs": [],
   "source": [
    "# Feature Normalization \n",
    "X_train = X_train.astype('float32'); X_cv= X_cv.astype('float32'); X_test = X_test.astype('float32')\n",
    "X_train /= 255; X_cv /= 255; X_test /= 255\n",
    "\n",
    "# Convert labels to One Hot Encoded\n",
    "num_digits = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_digits)\n",
    "y_cv = keras.utils.to_categorical(y_cv, num_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "6667ca35-44ff-43f3-b88b-27b787be4ee0",
    "_execution_state": "busy",
    "_uuid": "3fdf37a538504f4e5288cbb8b70a719c2689caca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Printing 2 examples of labels after conversion\n",
    "print(y_train[0]) # 2\n",
    "print(y_train[3]) # 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7d4e437c-12ea-4bad-a580-5504e8a77da0",
    "_execution_state": "idle",
    "_uuid": "0776b5f2aff1ebb6f12c2a9ee8e93013c690caf6"
   },
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8f441392-a707-499c-8816-00c8aa1a7757",
    "_execution_state": "idle",
    "_uuid": "064d83d74bf2e0842b21dcb3cc93f8427b04b6ea"
   },
   "source": [
    "We proceed by fitting several simple neural network models using Keras (with TensorFlow as our backend) and collect their accuracy. The model that performs the best on the validation set will be used as the model of choice for the competition.\n",
    "\n",
    "Model 1: Simple Neural Network with 4 layers (300, 100, 100, 200)\n",
    "\n",
    "In our first model, we will use the Keras library to train a neural network with the activation function set as ReLu. To determine which class to output, we will rely on the SoftMax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "be9af3d4-ddac-4f85-945f-bd1cdf09fc15",
    "_execution_state": "busy",
    "_uuid": "b88da407b6dab83e54b5380e0e62459577949932"
   },
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "74eac473-a6cb-4356-a982-ef3cb6c971de",
    "_execution_state": "busy",
    "_uuid": "f97a558010d88407363bbb08fa00e7c87a3d6ceb"
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "bf09781e-6376-4f2d-a872-6292d466f657",
    "_execution_state": "busy",
    "_uuid": "aaf8fe1cd6cb32675f0ed5009d7bc31d6f71e4ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_4 (Dense)       (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 297,910\n",
      "Trainable params: 297,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Our model would have '6' layers - input layer, 4 hidden layer and 1 output layer\n",
    "model = Model(Inp, output)\n",
    "model.summary() # We have 297,910 parameters to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "906807f1-ed62-4dee-a423-5f15842fb28f",
    "_execution_state": "busy",
    "_uuid": "c4ea7858fbdf41308dcdb5d373af11484d5b5140"
   },
   "outputs": [],
   "source": [
    "# Insert Hyperparameters\n",
    "learning_rate = 0.1\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "sgd = optimizers.SGD(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "5678ce6d-58eb-4394-9a77-b67c94c2ca4f",
    "_execution_state": "busy",
    "_uuid": "775193de659c41c949495a2afa3b14024a2536a7"
   },
   "outputs": [],
   "source": [
    "# We rely on the plain vanilla Stochastic Gradient Descent as our optimizing methodology\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "1a547d04-6aeb-4c76-8fbc-7fbca1b50b2a",
    "_execution_state": "busy",
    "_uuid": "4960dfa65394fb0314ce9cb7af63d48709a39d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 1.8541 - accuracy: 0.4985 - val_loss: 1.0047 - val_accuracy: 0.7601\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.6482 - accuracy: 0.8293 - val_loss: 0.4640 - val_accuracy: 0.8720\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.4099 - accuracy: 0.8834 - val_loss: 0.3621 - val_accuracy: 0.8976\n",
      "Epoch 4/20\n",
      " - 2s - loss: 0.3377 - accuracy: 0.9028 - val_loss: 0.3123 - val_accuracy: 0.9102\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.2980 - accuracy: 0.9140 - val_loss: 0.2893 - val_accuracy: 0.9175\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.2684 - accuracy: 0.9226 - val_loss: 0.2651 - val_accuracy: 0.9238\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.2454 - accuracy: 0.9296 - val_loss: 0.2558 - val_accuracy: 0.9257\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.2273 - accuracy: 0.9352 - val_loss: 0.2322 - val_accuracy: 0.9338\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.2102 - accuracy: 0.9378 - val_loss: 0.2176 - val_accuracy: 0.9363\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.1952 - accuracy: 0.9439 - val_loss: 0.2053 - val_accuracy: 0.9398\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.1828 - accuracy: 0.9468 - val_loss: 0.1954 - val_accuracy: 0.9427\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.1707 - accuracy: 0.9504 - val_loss: 0.1849 - val_accuracy: 0.9450\n",
      "Epoch 13/20\n",
      " - 2s - loss: 0.1612 - accuracy: 0.9530 - val_loss: 0.1804 - val_accuracy: 0.9455\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.1515 - accuracy: 0.9562 - val_loss: 0.1763 - val_accuracy: 0.9470\n",
      "Epoch 15/20\n",
      " - 2s - loss: 0.1431 - accuracy: 0.9588 - val_loss: 0.1656 - val_accuracy: 0.9500\n",
      "Epoch 16/20\n",
      " - 2s - loss: 0.1353 - accuracy: 0.9604 - val_loss: 0.1594 - val_accuracy: 0.9531\n",
      "Epoch 17/20\n",
      " - 2s - loss: 0.1289 - accuracy: 0.9622 - val_loss: 0.1546 - val_accuracy: 0.9531\n",
      "Epoch 18/20\n",
      " - 2s - loss: 0.1217 - accuracy: 0.9646 - val_loss: 0.1478 - val_accuracy: 0.9558\n",
      "Epoch 19/20\n",
      " - 2s - loss: 0.1157 - accuracy: 0.9668 - val_loss: 0.1472 - val_accuracy: 0.9555\n",
      "Epoch 20/20\n",
      " - 2s - loss: 0.1100 - accuracy: 0.9683 - val_loss: 0.1409 - val_accuracy: 0.9582\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(X_train, y_train,\n",
    "                     batch_size = batch_size,\n",
    "                     epochs = training_epochs,\n",
    "                     verbose = 2,\n",
    "                     validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2fee2dfc-23d2-480f-918e-54fb5386c4ea",
    "_execution_state": "idle",
    "_uuid": "6121bf7f8adbeaf85b3aef6167444b555b920440"
   },
   "source": [
    "Using a 4 layer neural network with:\n",
    "\n",
    "1. 20 training epochs\n",
    "2. A training batch size of 100\n",
    "3. Hidden layers set as (300, 100, 100, 200)\n",
    "4. Learning rate of 0.1\n",
    "\n",
    "Achieved a training score of around 96-98% and a test score of around 95 - 97%.\n",
    "\n",
    "Can we do better if we were to change the optimizer? To find out, we use the Adam optimizer for our second model, while maintaining the same parameter values for all other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "4e7a2ba9-ac08-4355-a37f-2336220cfda7",
    "_execution_state": "busy",
    "_uuid": "3d9c3ffb9722b640ea0682e5826971045091db66"
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "# We rely on ADAM as our optimizing methodology\n",
    "adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "model2 = Model(Inp, output)\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "e4470ac7-6888-4b10-a4e5-8bd4e22301cf",
    "_execution_state": "busy",
    "_uuid": "7f94a2f9d7db89bf3fb28ecff64dbf7a496b0b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      " - 3s - loss: 0.3405 - accuracy: 0.8977 - val_loss: 0.1635 - val_accuracy: 0.9492\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.1268 - accuracy: 0.9610 - val_loss: 0.1290 - val_accuracy: 0.9611\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.0843 - accuracy: 0.9732 - val_loss: 0.1042 - val_accuracy: 0.9677\n",
      "Epoch 4/20\n",
      " - 3s - loss: 0.0623 - accuracy: 0.9801 - val_loss: 0.1313 - val_accuracy: 0.9608\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.0452 - accuracy: 0.9849 - val_loss: 0.1088 - val_accuracy: 0.9690\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.0403 - accuracy: 0.9867 - val_loss: 0.0968 - val_accuracy: 0.9735\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.0353 - accuracy: 0.9879 - val_loss: 0.0961 - val_accuracy: 0.9740\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.0248 - accuracy: 0.9925 - val_loss: 0.1102 - val_accuracy: 0.9729\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.0928 - val_accuracy: 0.9787\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.1174 - val_accuracy: 0.9705\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.1077 - val_accuracy: 0.9739\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.1083 - val_accuracy: 0.9733\n",
      "Epoch 13/20\n",
      " - 2s - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.1048 - val_accuracy: 0.9761\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.1319 - val_accuracy: 0.9710\n",
      "Epoch 15/20\n",
      " - 2s - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.1508 - val_accuracy: 0.9695\n",
      "Epoch 16/20\n",
      " - 2s - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.1042 - val_accuracy: 0.9776\n",
      "Epoch 17/20\n",
      " - 2s - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.1338 - val_accuracy: 0.9739\n",
      "Epoch 18/20\n",
      " - 2s - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.1114 - val_accuracy: 0.9762\n",
      "Epoch 19/20\n",
      " - 2s - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.1286 - val_accuracy: 0.9742\n",
      "Epoch 20/20\n",
      " - 2s - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.1135 - val_accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_train, y_train,\n",
    "                      batch_size = batch_size,\n",
    "                      epochs = training_epochs,\n",
    "                      verbose = 2,\n",
    "                      validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e5b9ec27-6585-4f51-be9e-9e86120f723a",
    "_execution_state": "idle",
    "_uuid": "beae0734aefb9f26144b556c753032b66fe99911"
   },
   "source": [
    "As it turns out, it does appear to be the case that the optimizer plays a crucial part in the validation score. In particular, the model which relies on 'Adam' as its optimizer tend to perform 1.5 - 2.5% better on average. Going forward, we will use 'Adam' as our optimizer of choice.\n",
    "\n",
    "What if we changed the learning rate from 0.1 to 0.01, or 0.5? Will it have any impact on the accuracy?\n",
    "Model 2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "da528246-4223-42ff-af96-cd3419c34507",
    "_execution_state": "busy",
    "_uuid": "d2e88469ac4ed8ac19a195d71941178d8cdb7c32"
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "learning_rate = 0.01\n",
    "adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "model2a = Model(Inp, output)\n",
    "\n",
    "model2a.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "847391bb-4640-4117-a35e-5593d823bbc4",
    "_execution_state": "busy",
    "_uuid": "8e397c8d027a4f27b1f72ac9333de51cbc335cd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      " - 3s - loss: 0.3382 - accuracy: 0.8982 - val_loss: 0.1951 - val_accuracy: 0.9415\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.1244 - accuracy: 0.9616 - val_loss: 0.1244 - val_accuracy: 0.9626\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.0834 - accuracy: 0.9742 - val_loss: 0.0918 - val_accuracy: 0.9724\n",
      "Epoch 4/20\n",
      " - 2s - loss: 0.0594 - accuracy: 0.9808 - val_loss: 0.1027 - val_accuracy: 0.9701\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.0468 - accuracy: 0.9849 - val_loss: 0.0961 - val_accuracy: 0.9733\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.0328 - accuracy: 0.9898 - val_loss: 0.1082 - val_accuracy: 0.9707\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.1212 - val_accuracy: 0.9701\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.1058 - val_accuracy: 0.9742\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.0215 - accuracy: 0.9935 - val_loss: 0.1092 - val_accuracy: 0.9710\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.0245 - accuracy: 0.9924 - val_loss: 0.1133 - val_accuracy: 0.9715\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.1225 - val_accuracy: 0.9732\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.1070 - val_accuracy: 0.9768\n",
      "Epoch 13/20\n",
      " - 2s - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.1105 - val_accuracy: 0.9768\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.1255 - val_accuracy: 0.9726\n",
      "Epoch 15/20\n",
      " - 2s - loss: 0.0177 - accuracy: 0.9940 - val_loss: 0.1360 - val_accuracy: 0.9699\n",
      "Epoch 16/20\n",
      " - 2s - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.1051 - val_accuracy: 0.9786\n",
      "Epoch 17/20\n",
      " - 2s - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.1087 - val_accuracy: 0.9788\n",
      "Epoch 18/20\n",
      " - 2s - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1275 - val_accuracy: 0.9765\n",
      "Epoch 19/20\n",
      " - 2s - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.1160 - val_accuracy: 0.9780\n",
      "Epoch 20/20\n",
      " - 2s - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.1221 - val_accuracy: 0.9786\n"
     ]
    }
   ],
   "source": [
    "history2a = model2a.fit(X_train, y_train,\n",
    "                        batch_size = batch_size,\n",
    "                        epochs = training_epochs,\n",
    "                        verbose = 2,\n",
    "                        validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "590e8fcc-b3da-41e7-984d-d5d53aa5cb81",
    "_execution_state": "idle",
    "_uuid": "42520a694b6caf71582c6d5aad5a8599d52e5096"
   },
   "source": [
    "Model 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "18ef2f7d-f9a6-4609-8fd4-7d98cb7bc82f",
    "_execution_state": "busy",
    "_uuid": "fbc0a1e06296ada3553c9328e48861645680bbf9"
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "learning_rate = 0.5\n",
    "adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "model2b = Model(Inp, output)\n",
    "\n",
    "model2b.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "ad3ac83b-a040-42ba-9d62-2203e62a82ec",
    "_execution_state": "busy",
    "_uuid": "c2e1a75c4a95acdfd3d5ce81af0c20bce995ca24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      "33600/33600 [==============================] - 3s 83us/step - loss: 0.3336 - accuracy: 0.9034 - val_loss: 0.1445 - val_accuracy: 0.9580\n",
      "Epoch 2/20\n",
      "33600/33600 [==============================] - 2s 74us/step - loss: 0.1220 - accuracy: 0.9628 - val_loss: 0.1310 - val_accuracy: 0.9598\n",
      "Epoch 3/20\n",
      "33600/33600 [==============================] - 2s 74us/step - loss: 0.0783 - accuracy: 0.9753 - val_loss: 0.0977 - val_accuracy: 0.9706\n",
      "Epoch 4/20\n",
      "33600/33600 [==============================] - 2s 74us/step - loss: 0.0560 - accuracy: 0.9828 - val_loss: 0.1107 - val_accuracy: 0.9686\n",
      "Epoch 5/20\n",
      "33600/33600 [==============================] - 2s 73us/step - loss: 0.0495 - accuracy: 0.9833 - val_loss: 0.0896 - val_accuracy: 0.9745\n",
      "Epoch 6/20\n",
      "33600/33600 [==============================] - 2s 74us/step - loss: 0.0380 - accuracy: 0.9881 - val_loss: 0.0952 - val_accuracy: 0.9720\n",
      "Epoch 7/20\n",
      "33600/33600 [==============================] - 2s 74us/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.1012 - val_accuracy: 0.9755\n",
      "Epoch 8/20\n",
      "33600/33600 [==============================] - 2s 73us/step - loss: 0.0253 - accuracy: 0.9918 - val_loss: 0.0955 - val_accuracy: 0.9762\n",
      "Epoch 9/20\n",
      "33600/33600 [==============================] - 3s 74us/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.1082 - val_accuracy: 0.9730\n",
      "Epoch 10/20\n",
      "33600/33600 [==============================] - 2s 73us/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 0.1125 - val_accuracy: 0.9723\n",
      "Epoch 11/20\n",
      "33600/33600 [==============================] - 2s 74us/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.1230 - val_accuracy: 0.9724\n",
      "Epoch 12/20\n",
      "33600/33600 [==============================] - 2s 73us/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.0952 - val_accuracy: 0.9780\n",
      "Epoch 13/20\n",
      "33600/33600 [==============================] - 2s 74us/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.1007 - val_accuracy: 0.9762\n",
      "Epoch 14/20\n",
      "33600/33600 [==============================] - 2s 74us/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.1219 - val_accuracy: 0.9719\n",
      "Epoch 15/20\n",
      "33600/33600 [==============================] - 2s 74us/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.1176 - val_accuracy: 0.9729\n",
      "Epoch 16/20\n",
      "33600/33600 [==============================] - 3s 75us/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.1061 - val_accuracy: 0.9761\n",
      "Epoch 17/20\n",
      "33600/33600 [==============================] - 3s 75us/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.1414 - val_accuracy: 0.9714\n",
      "Epoch 18/20\n",
      "33600/33600 [==============================] - 2s 73us/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.1094 - val_accuracy: 0.9774\n",
      "Epoch 19/20\n",
      "33600/33600 [==============================] - 3s 75us/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.1208 - val_accuracy: 0.9750\n",
      "Epoch 20/20\n",
      "33600/33600 [==============================] - 2s 74us/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.1260 - val_accuracy: 0.9744\n"
     ]
    }
   ],
   "source": [
    "history2b = model2b.fit(X_train, y_train,\n",
    "                        batch_size = batch_size,\n",
    "                        epochs = training_epochs,\n",
    "                            validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9189bb25-f243-4edf-a7a0-943ec633760d",
    "_execution_state": "idle",
    "_uuid": "a36eb4079d02e6d3997d107fc5e3dd3a452a0fc9"
   },
   "source": [
    "The accuracy, as measured by the 3 different learning rates 0.01, 0.1 and 0.5 are around 98%, 97% and 98% respectively. As there are no considerable gains by changing the learning rates, we stick with the default learning rate of 0.01.\n",
    "\n",
    "We proceed to fit a neural network with 5 hidden layers with the features in the hidden layer set as (300, 100, 100, 100, 200) respectively. To ensure that the two models are comparable, we will set the training epochs as 20, and the training batch size as 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "25d57f65-533c-432b-bd4a-a3127101d4bb",
    "_execution_state": "busy",
    "_uuid": "c19270be516858cca76b3479417e4017877896b1"
   },
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 100\n",
    "n_hidden_5 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "d179df94-04b5-4d1e-ab7f-882a72442837",
    "_execution_state": "busy",
    "_uuid": "c919e5d20e55f0c86152efbb729feeb0292abf0a"
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "x = Dense(n_hidden_5, activation='relu', name = \"Hidden_Layer_5\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "04f2f013-41ee-48a7-9204-cfe8b748e09c",
    "_execution_state": "busy",
    "_uuid": "db189665726670192df8ed9e9758e908821f629b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_4 (Dense)       (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_5 (Dense)       (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 308,010\n",
      "Trainable params: 308,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Our model would have '7' layers - input layer, 5 hidden layer and 1 output layer\n",
    "model3 = Model(Inp, output)\n",
    "model3.summary() # We have 308,010 parameters to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "3da4e128-5987-4fb3-a2c7-93420c844d1d",
    "_execution_state": "busy",
    "_uuid": "304ab7710bc6f2e56d698cc232fadbba6886b664"
   },
   "outputs": [],
   "source": [
    "# We rely on 'Adam' as our optimizing methodology\n",
    "adam = keras.optimizers.Adam(lr=0.01)\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "f7ac3e43-bf76-488d-8ec6-31ec98228ee6",
    "_execution_state": "busy",
    "_uuid": "986fc367bbd1fc9767c30a03324c4d18e3bfd0d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      "33600/33600 [==============================] - 3s 84us/step - loss: 0.3602 - accuracy: 0.8930 - val_loss: 0.1909 - val_accuracy: 0.9440\n",
      "Epoch 2/20\n",
      "33600/33600 [==============================] - 3s 76us/step - loss: 0.1276 - accuracy: 0.9603 - val_loss: 0.1247 - val_accuracy: 0.9630\n",
      "Epoch 3/20\n",
      "33600/33600 [==============================] - 3s 75us/step - loss: 0.0848 - accuracy: 0.9742 - val_loss: 0.1114 - val_accuracy: 0.9662\n",
      "Epoch 4/20\n",
      "33600/33600 [==============================] - 3s 76us/step - loss: 0.0619 - accuracy: 0.9805 - val_loss: 0.1020 - val_accuracy: 0.9704\n",
      "Epoch 5/20\n",
      "33600/33600 [==============================] - 3s 76us/step - loss: 0.0499 - accuracy: 0.9838 - val_loss: 0.0970 - val_accuracy: 0.9718\n",
      "Epoch 6/20\n",
      "33600/33600 [==============================] - 3s 75us/step - loss: 0.0411 - accuracy: 0.9874 - val_loss: 0.0905 - val_accuracy: 0.9750\n",
      "Epoch 7/20\n",
      "33600/33600 [==============================] - 3s 75us/step - loss: 0.0357 - accuracy: 0.9883 - val_loss: 0.1114 - val_accuracy: 0.9721\n",
      "Epoch 8/20\n",
      "33600/33600 [==============================] - 3s 76us/step - loss: 0.0281 - accuracy: 0.9910 - val_loss: 0.1251 - val_accuracy: 0.9690\n",
      "Epoch 9/20\n",
      "33600/33600 [==============================] - 3s 77us/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.1136 - val_accuracy: 0.9710\n",
      "Epoch 10/20\n",
      "33600/33600 [==============================] - 3s 75us/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.1172 - val_accuracy: 0.9720\n",
      "Epoch 11/20\n",
      "33600/33600 [==============================] - 3s 76us/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.1163 - val_accuracy: 0.9730\n",
      "Epoch 12/20\n",
      "33600/33600 [==============================] - 3s 76us/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 0.1243 - val_accuracy: 0.9717\n",
      "Epoch 13/20\n",
      "33600/33600 [==============================] - 3s 76us/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.1232 - val_accuracy: 0.9725\n",
      "Epoch 14/20\n",
      "33600/33600 [==============================] - 3s 75us/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.1372 - val_accuracy: 0.9690\n",
      "Epoch 15/20\n",
      "33600/33600 [==============================] - 3s 75us/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.1233 - val_accuracy: 0.9764\n",
      "Epoch 16/20\n",
      "33600/33600 [==============================] - 3s 76us/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.1179 - val_accuracy: 0.9751\n",
      "Epoch 17/20\n",
      "33600/33600 [==============================] - 3s 76us/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.1244 - val_accuracy: 0.9782\n",
      "Epoch 18/20\n",
      "33600/33600 [==============================] - 3s 75us/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.1236 - val_accuracy: 0.9744\n",
      "Epoch 19/20\n",
      "33600/33600 [==============================] - 3s 76us/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.1236 - val_accuracy: 0.9743\n",
      "Epoch 20/20\n",
      "33600/33600 [==============================] - 3s 76us/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.1255 - val_accuracy: 0.9762\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(X_train, y_train,\n",
    "                      batch_size = batch_size,\n",
    "                      epochs = training_epochs,\n",
    "                      validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d6d4f220-5431-4221-be1d-2a6ceae86ac9",
    "_execution_state": "idle",
    "_uuid": "595cd530b900cf25bb1774eabd22afff49b980df"
   },
   "source": [
    "Compared to our first model, adding an additional layer did not significantly improve the accuracy from our previous model. However, there are computational costs (in terms of complexity) in implementing an additional layer in our neural network. Given that the benefits of an additional layer are low while the costs are high, we will stick with the 4 layer neural network.\n",
    "\n",
    "We now proceed to include dropout (dropout rate of 0.3) in our second model to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "9054eb9b-e655-415c-93e7-3f0ca45d84ac",
    "_execution_state": "busy",
    "_uuid": "608b71d5bd8dc23df6d916e7371887fd52dd24d8"
   },
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "0541e860-b2f6-43cd-8d00-254e9daf775a",
    "_execution_state": "busy",
    "_uuid": "d6335bd113992a8898679d1a5d09ed2eda3fe5af"
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "95f4299a-0e1c-4dca-b7d5-839e7a5e8fc8",
    "_execution_state": "busy",
    "_uuid": "08e56562d89bcd25756bc5bbbb4f33ceb87f106e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_4 (Dense)       (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 297,910\n",
      "Trainable params: 297,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Our model would have '6' layers - input layer, 4 hidden layer and 1 output layer\n",
    "model4 = Model(Inp, output)\n",
    "model4.summary() # We have 297,910 parameters to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "ed1c4a9d-730e-4e4d-8a25-4448d877d5b6",
    "_execution_state": "busy",
    "_uuid": "2328fa07b0f4c63448b0c30b7ae450df2b0fe3be"
   },
   "outputs": [],
   "source": [
    "model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "8543232e-da2b-46ce-9a5e-06e6283b854a",
    "_execution_state": "busy",
    "_uuid": "986af85bbaf1b212b00cf28dc9204339b717ee48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      "33600/33600 [==============================] - 3s 95us/step - loss: 0.5821 - accuracy: 0.8137 - val_loss: 0.1895 - val_accuracy: 0.9423\n",
      "Epoch 2/20\n",
      "33600/33600 [==============================] - 3s 84us/step - loss: 0.2281 - accuracy: 0.9334 - val_loss: 0.1350 - val_accuracy: 0.9606\n",
      "Epoch 3/20\n",
      "33600/33600 [==============================] - 3s 85us/step - loss: 0.1768 - accuracy: 0.9492 - val_loss: 0.1135 - val_accuracy: 0.9664\n",
      "Epoch 4/20\n",
      "33600/33600 [==============================] - 3s 84us/step - loss: 0.1422 - accuracy: 0.9585 - val_loss: 0.1071 - val_accuracy: 0.9693\n",
      "Epoch 5/20\n",
      "33600/33600 [==============================] - 3s 84us/step - loss: 0.1218 - accuracy: 0.9634 - val_loss: 0.0935 - val_accuracy: 0.9742\n",
      "Epoch 6/20\n",
      "33600/33600 [==============================] - 3s 84us/step - loss: 0.1063 - accuracy: 0.9680 - val_loss: 0.0861 - val_accuracy: 0.9744\n",
      "Epoch 7/20\n",
      "33600/33600 [==============================] - 3s 84us/step - loss: 0.0965 - accuracy: 0.9715 - val_loss: 0.0931 - val_accuracy: 0.9736\n",
      "Epoch 8/20\n",
      "33600/33600 [==============================] - 3s 92us/step - loss: 0.0880 - accuracy: 0.9743 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 9/20\n",
      "33600/33600 [==============================] - 3s 87us/step - loss: 0.0805 - accuracy: 0.9762 - val_loss: 0.0923 - val_accuracy: 0.9754\n",
      "Epoch 10/20\n",
      "33600/33600 [==============================] - 3s 85us/step - loss: 0.0764 - accuracy: 0.9776 - val_loss: 0.0910 - val_accuracy: 0.9769\n",
      "Epoch 11/20\n",
      "33600/33600 [==============================] - 3s 85us/step - loss: 0.0689 - accuracy: 0.9795 - val_loss: 0.0863 - val_accuracy: 0.9760\n",
      "Epoch 12/20\n",
      "33600/33600 [==============================] - 3s 84us/step - loss: 0.0659 - accuracy: 0.9806 - val_loss: 0.0871 - val_accuracy: 0.9773\n",
      "Epoch 13/20\n",
      "33600/33600 [==============================] - 3s 84us/step - loss: 0.0614 - accuracy: 0.9811 - val_loss: 0.0862 - val_accuracy: 0.9785\n",
      "Epoch 14/20\n",
      "33600/33600 [==============================] - 3s 84us/step - loss: 0.0582 - accuracy: 0.9827 - val_loss: 0.0926 - val_accuracy: 0.9761\n",
      "Epoch 15/20\n",
      "33600/33600 [==============================] - 3s 84us/step - loss: 0.0541 - accuracy: 0.9839 - val_loss: 0.0866 - val_accuracy: 0.9786\n",
      "Epoch 16/20\n",
      "33600/33600 [==============================] - 3s 84us/step - loss: 0.0560 - accuracy: 0.9832 - val_loss: 0.0937 - val_accuracy: 0.9775\n",
      "Epoch 17/20\n",
      "33600/33600 [==============================] - 3s 85us/step - loss: 0.0503 - accuracy: 0.9855 - val_loss: 0.0913 - val_accuracy: 0.9798\n",
      "Epoch 18/20\n",
      "33600/33600 [==============================] - 3s 84us/step - loss: 0.0480 - accuracy: 0.9856 - val_loss: 0.0794 - val_accuracy: 0.9806\n",
      "Epoch 19/20\n",
      "33600/33600 [==============================] - 3s 84us/step - loss: 0.0464 - accuracy: 0.9858 - val_loss: 0.0930 - val_accuracy: 0.9789\n",
      "Epoch 20/20\n",
      "33600/33600 [==============================] - 3s 84us/step - loss: 0.0461 - accuracy: 0.9862 - val_loss: 0.0870 - val_accuracy: 0.9788\n"
     ]
    }
   ],
   "source": [
    "history = model4.fit(X_train, y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = training_epochs,\n",
    "                    validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "07d922d5-ec8a-4b3b-8e02-a0aafc3ad52a",
    "_execution_state": "idle",
    "_uuid": "ad316467bedf355759a181d353850f1d365ee05b"
   },
   "source": [
    "With a validation score of close to 98%, we proceed to use this model to predict for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "d07359be-0cb3-4e0b-9d3e-d8953f67211d",
    "_execution_state": "busy",
    "_uuid": "8ae888d3b351dca6417ed4e3830688f1b75701ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      9\n",
       "4        5      3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = pd.DataFrame(model4.predict(X_test, batch_size=200))\n",
    "test_pred = pd.DataFrame(test_pred.idxmax(axis = 1))\n",
    "test_pred.index.name = 'ImageId'\n",
    "test_pred = test_pred.rename(columns = {0: 'Label'}).reset_index()\n",
    "test_pred['ImageId'] = test_pred['ImageId'] + 1\n",
    "\n",
    "test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "2a132e08-be9b-4efa-89bc-6fc9952b6fde",
    "_execution_state": "busy",
    "_uuid": "02492c073118b428bb2c4937840e12c35f1a0fd4"
   },
   "outputs": [],
   "source": [
    "test_pred.to_csv('mnist_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1510902d-0b15-4b5b-9268-e4f8e1544222",
    "_execution_state": "idle",
    "_uuid": "515b774eafeacae442e19e3fae989a49f6904837"
   },
   "source": [
    "Using this model, we are able to achieve a score of 0.976, which places us at the top 55th percentile!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
