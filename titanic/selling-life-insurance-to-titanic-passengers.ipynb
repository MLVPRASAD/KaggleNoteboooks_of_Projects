{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5f3ccaaac79bc50906ae2b831c1089965838753e"
   },
   "source": [
    "# Would you sell a life insurance to the Titanic passengers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5265419c265046340ee4b4d462513386f631f9cb"
   },
   "source": [
    "Thanks for **UPVOTING** this kernel! Trying to become a Kernel Expert. 👍\n",
    "\n",
    "> Check out other interesting projects related to Titanic by Pavlo Fesenko:\n",
    "- [(kernel) How to extend Titanic dataset using Wikipedia?](https://www.kaggle.com/pavlofesenko/extending-titanic-dataset-using-wikipedia)\n",
    "- [(dataset) Titanic extended (Kaggle + Wikipedia)](https://www.kaggle.com/pavlofesenko/titanic-extended)\n",
    "\n",
    "---\n",
    "## Table of contents:\n",
    "1. [Problem description](#1.-Problem-description)\n",
    "2. [How is this problem different from the regular classification?](#2.-How-is-this-problem-different-from-the-regular-classification?)\n",
    "3. [Preparing the data](#3.-Preparing-the-data)\n",
    "4. [Training the model and adjusting precision](#4.-Training-the-model-and-adjusting-precision)\n",
    "5. [Conclusion](#5.-Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0b98fa7f26a4e7bc92dcd51bda32a2b2b7ecd1b6"
   },
   "source": [
    "## 1. Problem description\n",
    "\n",
    "Imagine that you have to decide whether to sell life insurances to the Titanic passengers and you know in advance that the ship is going to sink. Moreover, you have somehow obtained the anonymized features of the victims and survivors.\n",
    "\n",
    "> *Could you minimize the number of insurance claims from the victims and at the same time maximize the total number of insurances that are sold to the passengers*?\n",
    "\n",
    "This approach could be, for example, used by the insurance agencies that sell life insurances for high-risk clients with high-risk profession, habits, diseases, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9abde72048a1bba25cb9dbebcfc1cc82695f51d1"
   },
   "source": [
    "## 2. How is this problem different from the regular classification?\n",
    "\n",
    "<img align=\"right\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/350px-Precisionrecall.svg.png\">\n",
    "\n",
    "Let's have a look at the results of the classification model that will be further described in Part 4:\n",
    "* Correct predictions: 177 (survivors 61, victims 116)\n",
    "* Wrong predictions: 46 (survivors 23, victims 23)\n",
    "\n",
    "The overall accuracy score of this model seems to be quite good 177 / (177 + 46) = 0.79 but is it also good for our particular problem?\n",
    "\n",
    "Note that this model has wrongly predicted 23 survivors (that actually died) meaning that the insurance agency has sold them insurances and now has to pay 23 insurance claims to the relatives of these victims. This is a huge cost! Ideally we want the number of wrongly predicted survivors to be 0. This type of wrong predictions is called *false positives* (see the figure on the right, cited from [Wikipedia](https://en.wikipedia.org/wiki/Precision_and_recall)).\n",
    "\n",
    "On the other hand, the model has wrongly predicted 23 victims (that actually survived) meaning that the agency hasn't sold 23 insurances to these people and lost potential customers. Nevertheless, this loss is significantly lower compared to the previous one since the cost of the insurance package is typically much lower than the cost of the insurance claim. This type of wrong predictions is called *false negatives* (see the figure).\n",
    "\n",
    "To conclude, the incurance agency would prefer to **minimize the number of false positives** even if it might increase the number of false negatives.\n",
    "\n",
    "For this purpose we will use the concepts of *precision* and *recall* that are defined below in the figure. As one can see from this definitions, **maximizing the precision minimizes the number of false positives**.\n",
    "\n",
    "But how do we adjust our model to maximize the precision of the survivors? To make the long story short, we will need to adjust the threshold for class probabilities predicted by our model using a *Precision-Recall (or PR) curve*. More on that will come in the Part 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92608eb6044bcef85addd520d67a6ed6109baf3a"
   },
   "source": [
    "## 3. Preparing the data\n",
    "\n",
    "Before we build our model using machine learning algorithms, let's prepare our dataset. We will go through the following stages:\n",
    "1. Importing the data\n",
    "2. Selecting the feature matrix `X` and the target column `y` (*supervised learning*)\n",
    "3. Scaling numeric features\n",
    "4. Encoding categorical features\n",
    "5. Splitting the whole dataset into training and testing datasets\n",
    "\n",
    "In the very beginning don't forget to import the required libraries. =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "4ec45db34adb6115b815190b1603bff0a4b340d2"
   },
   "outputs": [],
   "source": [
    "# Silencing warnings from scikit-learn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import model_selection, linear_model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf4901bdb512278667b520d73a3c710acba1d6f8"
   },
   "source": [
    "For the purpose of this demonstration we will only use the file `train.csv` that contains the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "f817de5ec48cff8d06141e0d3f45bb10d8ab991c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass    ...        Fare Cabin  Embarked\n",
       "0            1         0       3    ...      7.2500   NaN         S\n",
       "1            2         1       1    ...     71.2833   C85         C\n",
       "2            3         1       3    ...      7.9250   NaN         S\n",
       "3            4         1       1    ...     53.1000  C123         S\n",
       "4            5         0       3    ...      8.0500   NaN         S\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data\n",
    "data = pd.read_csv('../input/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bbd67f8da472fdfc27cd3cc28cb3ae72c7b998a6"
   },
   "source": [
    "The columns `PassengerId`, `Name`, `Ticket`, `Cabin` are excluded from the feature matrix `X` because the column `PassengerId` doesn't provide any useful information and the columns `Name`, `Ticket`, `Cabin` don't represent neither numeric nor categorical features. These columns can be used to generarte new features but it is an advanced topic and isn't covered in this kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "a4abbbe07b31dffc3a6fec9d679ce8ea1d25089a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0       3    male  22.0      1      0   7.2500        S\n",
       "1       1  female  38.0      1      0  71.2833        C\n",
       "2       3  female  26.0      0      0   7.9250        S\n",
       "3       1  female  35.0      1      0  53.1000        S\n",
       "4       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the target column and the feature matrix\n",
    "y = data['Survived']\n",
    "X = data.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "db7b5a3449a0768df46ff6aa4e6a9b5d279b3248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 7 columns):\n",
      "Pclass      891 non-null int64\n",
      "Sex         891 non-null object\n",
      "Age         714 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Embarked    889 non-null object\n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 48.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Checking the types of the columns and if they contain missing values\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8492f1f76579a556e76a81ea51fdfd24c6935369"
   },
   "source": [
    "The numeric and categorical features are separated since different prepocessing strategies are applied to them. Note that `Pclass` can be also considered a categorical feature. But since there is an order in the class numbers according to the luxury level (*ordinal feature*), it can be treated as numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "6e92a3ccdf2fa139db3c8d65789df4cf2df96bf9"
   },
   "outputs": [],
   "source": [
    "# Separating the feature matrix according to numeric and categorical features\n",
    "num_feat = X.select_dtypes('number').columns.values\n",
    "cat_feat = X.select_dtypes('object').columns.values\n",
    "X_num = X[num_feat]\n",
    "X_cat = X[cat_feat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b788a3c7068549d5c1ddc37efe0b412987e62d0"
   },
   "source": [
    "*Scaling* the numerical features below is important for convergence in some machine learning algorithms (for example, based on gradient descent). As a scaling method we chose standardization. Note that the NaN elements are filled in with the mean values of the corresponding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "5a4044a1d5a58b93ec8ecd568946b7e77bc58518"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.826913</td>\n",
       "      <td>-0.530005</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.502163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.565228</td>\n",
       "      <td>0.571430</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>0.786404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.826913</td>\n",
       "      <td>-0.254646</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.488580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.565228</td>\n",
       "      <td>0.364911</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>0.420494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.826913</td>\n",
       "      <td>0.364911</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.486064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass       Age     SibSp     Parch      Fare\n",
       "0  0.826913 -0.530005  0.432550 -0.473408 -0.502163\n",
       "1 -1.565228  0.571430  0.432550 -0.473408  0.786404\n",
       "2  0.826913 -0.254646 -0.474279 -0.473408 -0.488580\n",
       "3 -1.565228  0.364911  0.432550 -0.473408  0.420494\n",
       "4  0.826913  0.364911 -0.474279 -0.473408 -0.486064"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling the numeric features using standardization\n",
    "X_num = (X_num - X_num.mean()) / X_num.std()\n",
    "X_num = X_num.fillna(X_num.mean())\n",
    "X_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a8bf261c3efdc4e29b4b96a07ac947ca8eb151a"
   },
   "source": [
    "*Encoding* the categorical features below is required since the machine learning algorithms work with numbers and not with strings. As an encoding method we chose one-hot encoding with dummmy variables. Note that the NaN elements are encoded with all 0 in the dummy variables so their additional filling is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "00dd8762963e7936efffc2fdeece888d1de7a352"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S\n",
       "0           0         1           0           0           1\n",
       "1           1         0           1           0           0\n",
       "2           1         0           0           0           1\n",
       "3           1         0           0           0           1\n",
       "4           0         1           0           0           1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding the categorical features using one-hot encoding\n",
    "X_cat = pd.get_dummies(X_cat)\n",
    "X_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "428e0e9a6d90ff3e43f321f04ae35d8fe430831e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.826913</td>\n",
       "      <td>-0.530005</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.502163</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.565228</td>\n",
       "      <td>0.571430</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>0.786404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.826913</td>\n",
       "      <td>-0.254646</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.488580</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.565228</td>\n",
       "      <td>0.364911</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>0.420494</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.826913</td>\n",
       "      <td>0.364911</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.486064</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass       Age     SibSp     ...      Embarked_C  Embarked_Q  Embarked_S\n",
       "0  0.826913 -0.530005  0.432550     ...               0           0           1\n",
       "1 -1.565228  0.571430  0.432550     ...               1           0           0\n",
       "2  0.826913 -0.254646 -0.474279     ...               0           0           1\n",
       "3 -1.565228  0.364911  0.432550     ...               0           0           1\n",
       "4  0.826913  0.364911 -0.474279     ...               0           0           1\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining processed numeric and categorical features in one feature matrix\n",
    "X = pd.concat([X_num, X_cat], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6678e3ae474a3c430a649a17ade2b81099bc8916"
   },
   "source": [
    "The random state for the splitting below is fixed so that others could reproduce my results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "285dcbdb68b2146cbc100b6863fdf52146512927",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Splitting the final dataset into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b02459f153adf8e0a90185534fec43f41610af09"
   },
   "source": [
    "## 4. Training the model and adjusting precision\n",
    "\n",
    "As mentioned in the Part 1, to minimize the insurance claims from the victims we need to minimize the number of false positive errors or equivalently maximize the precision. This statement is obvious from the definition of the latter\n",
    "\n",
    "$$ \\text{Precision} = \\frac{\\text{true positives}}{\\text{true positives + false positives}} $$.\n",
    "\n",
    "In order to avoid false positives when predicting survived passengers, the classification threshold needs to clearly separate the training group of died passengers (true negatives or TN) from the rest (see the figure A below, cited from [Towards Data Science](https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65)).\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/800/1*J8kWRRekByVSJi8XDTSsgw.jpeg\">\n",
    "\n",
    "For example, for classification models that use a logistic loss function, this is a probability threshold (0.5 by default) for the outcome probabilities predicted by the model. If the predicted probability is higher than this threshold, the object is considered to be class \"1\" (survived passengers), otherwise the object is labeled to be class \"0\" (died passengers). To maximize the precision of survived passengers, the probability threshold needs to be much closer to 1.0 so that we only predict the survival of the passengers when the model thinks they have very high chances.\n",
    "\n",
    "Variation of the classification threshold changes not only precision but also recall. To visualize these changes data scientists make a *Precision-Recall (or PR) curve*. Using this curve we can identify the point of maximum precision and the corresponding threshold.\n",
    "\n",
    "For this problem I have chosen the classifier based on *stochastic gradient descent (or SGD)* with a logistic loss function. SGD is typically used for much larger datasets so other algorithms (for example, logistic regression) would be more appropriate here. However, SGD was one of the first classification algorithms that I learned and it is also great to demonstrate the importance of scaling the numeric features mentioned in Part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "c81c88c4cd7ecc0e86c5e36f3ef30534e57a0ea7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7937219730941704"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model and printing the accuracy score\n",
    "model = linear_model.SGDClassifier(loss='log', max_iter=2000, random_state=0) # Random state is fixed for reproducibility\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0ea4ae7a41789bbe42b0da0ab24234812e8ac8fc"
   },
   "source": [
    "Since SGD calculates the gradient only of the random part of the dataset (hence the name \"stochastic\"), the accuracy score might decrease after some of the iterations. Nevertheless, the score should be converging. This convergence should always be checked to ensure that the optimum point is reached. On the plot below the model converged after 1500 iterations so this or higher value should be used for the maximum number of iterations. Above we used 2000 iterations so it should suffice.\n",
    "\n",
    "**Try it yourself:** Scaling of the numeric features helps a lot with the convergence of the SGD classifier. Try to comment the code that does scaling and rerun all the cells. You will see that the convergence doesn't occur. In this case you need to set the parameter `learning_rate='constant'` and manually decrease the parameter `eta0` until the convergence occurs again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "20a99b03461c50a4e304da8c8a6895955e8db022"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking the convergence of the model\n",
    "n_iter = np.linspace(1, 3000)\n",
    "scores = np.array([])\n",
    "for n in n_iter:\n",
    "    model = linear_model.SGDClassifier(loss='log', max_iter=n, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    scores = np.append(scores, model.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(n_iter, scores)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9b3cacc2842c1369a8ad1e160e3d0b3a9f1bd290"
   },
   "source": [
    "Now that the convergence is confirmed, let's calculate the confusion matrix of our model. These values were used in Part 1 to explain the problem:\n",
    "\n",
    "* Correct predictions: 177 (survivors 61, victims 116)\n",
    "* Wrong predictions: 46 (survivors 23, victims 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "97278438ea325050accc8fd91805064279db478b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[116,  23],\n",
       "       [ 23,  61]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b2f6a66a0e8e1f5bc008685e0f05665b4c6c9dde"
   },
   "source": [
    "The precision score for the survived passengers is decent (see below) but not good enough for our specific problem that requires precision to be as high as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "06de20e97058ae5fe07f80c4573d6dc48da70441"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7261904761904762"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the precision score for survived passengers\n",
    "metrics.precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5bfb77f6dcb700c6f9a07e56bb7f6c89289f4927"
   },
   "source": [
    "Let's plot the Precision-Recall curve and find a point with a better precsion. Note that precision, recall and corresponding thresholds are obtained from the training dataset, not the testing dataset, to avoid biased scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "ed6baf1d3a38d052ef8917245f5a97e16072d636"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the Precision-Recall curve\n",
    "y_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "p, r, t = metrics.precision_recall_curve(y_train, y_proba_train)\n",
    "\n",
    "plt.plot(r, p)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1dd5ee37638a9509ac4c11584f73f8d999017fd0"
   },
   "source": [
    "The best precision of 1.0 is obtained for thresholds of 0.973211, 0.974678 and 1.0 (see the last 3 rows in the dataframe below). Let's pick up the threshold 0.973211 that corresponds to the highest recall among them. The higher the recall, the more true positives (or survived passengers) are predicted and the more insurances we will sell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "a44769f1d1bfb115dc9ca9ecf089f5981624d5b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.965561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.969996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.970968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.973211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.974678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Precision    Recall  Threshold\n",
       "558   0.800000  0.015504   0.965561\n",
       "559   0.750000  0.011628   0.969996\n",
       "560   0.666667  0.007752   0.970968\n",
       "561   1.000000  0.007752   0.973211\n",
       "562   1.000000  0.003876   0.974678"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the last 5 combinations of precision-recall-threshold\n",
    "prt = np.array(list(zip(p, r, t)))\n",
    "prt_df = pd.DataFrame(data=prt, columns=['Precision', 'Recall', 'Threshold'])\n",
    "prt_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf95e6eb045d262ac58dfcceae661a2af1f3415d"
   },
   "source": [
    "If we apply this threshold to the probabilities for our testing dataset, we will find out, however, that none of them pass the threshold. For us it means that no insurances will be sold at all. Therefore, we might want to lower our precision to the next largest value on the PR curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "9d6ecb68ae9a49cf61ffbfb92210c3b2a53feb03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the number of predicted survivors\n",
    "y_proba_test = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_proba_test >= 0.973211).astype(int)\n",
    "np.count_nonzero(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c15859bee6ffe418e452d4c96fce3c64239fa2cc"
   },
   "source": [
    "If you look again at the PR curve, you will notice that the precision rapidly drops at first but then recovers to 0.971429, the next highest value after 1.0 (see the row 529 below). This precision corresponds to the threshold 0.932465 and has much higher recall than in the previous case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "11d57bc004ae957237610e8c1d52dbaa2d24adff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.189922</td>\n",
       "      <td>0.903174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.906782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.182171</td>\n",
       "      <td>0.909994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.178295</td>\n",
       "      <td>0.910013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.174419</td>\n",
       "      <td>0.912081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.170543</td>\n",
       "      <td>0.913555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.914014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.914128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.158915</td>\n",
       "      <td>0.915179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.155039</td>\n",
       "      <td>0.918781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.151163</td>\n",
       "      <td>0.920793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.147287</td>\n",
       "      <td>0.921705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.143411</td>\n",
       "      <td>0.923146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.929883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.135659</td>\n",
       "      <td>0.930171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.131783</td>\n",
       "      <td>0.930619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.131783</td>\n",
       "      <td>0.932465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0.933675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.124031</td>\n",
       "      <td>0.934467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.937266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.937965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>0.940876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.108527</td>\n",
       "      <td>0.941774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.104651</td>\n",
       "      <td>0.942420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.100775</td>\n",
       "      <td>0.944107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.096899</td>\n",
       "      <td>0.945314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.950588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.089147</td>\n",
       "      <td>0.950926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.085271</td>\n",
       "      <td>0.951095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.951633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.077519</td>\n",
       "      <td>0.953706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.073643</td>\n",
       "      <td>0.953800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.954572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.065891</td>\n",
       "      <td>0.955712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.062016</td>\n",
       "      <td>0.956683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.957002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.054264</td>\n",
       "      <td>0.957779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.050388</td>\n",
       "      <td>0.958622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.959153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.042636</td>\n",
       "      <td>0.961715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.963038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>0.964177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.031008</td>\n",
       "      <td>0.964340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.027132</td>\n",
       "      <td>0.964521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.965484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.965561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.969996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.970968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.973211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.974678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Precision    Recall  Threshold\n",
       "513   0.960784  0.189922   0.903174\n",
       "514   0.960000  0.186047   0.906782\n",
       "515   0.959184  0.182171   0.909994\n",
       "516   0.958333  0.178295   0.910013\n",
       "517   0.957447  0.174419   0.912081\n",
       "518   0.956522  0.170543   0.913555\n",
       "519   0.955556  0.166667   0.914014\n",
       "520   0.954545  0.162791   0.914128\n",
       "521   0.953488  0.158915   0.915179\n",
       "522   0.952381  0.155039   0.918781\n",
       "523   0.951220  0.151163   0.920793\n",
       "524   0.950000  0.147287   0.921705\n",
       "525   0.948718  0.143411   0.923146\n",
       "526   0.947368  0.139535   0.929883\n",
       "527   0.945946  0.135659   0.930171\n",
       "528   0.944444  0.131783   0.930619\n",
       "529   0.971429  0.131783   0.932465\n",
       "530   0.970588  0.127907   0.933675\n",
       "531   0.969697  0.124031   0.934467\n",
       "532   0.968750  0.120155   0.937266\n",
       "533   0.967742  0.116279   0.937965\n",
       "534   0.966667  0.112403   0.940876\n",
       "535   0.965517  0.108527   0.941774\n",
       "536   0.964286  0.104651   0.942420\n",
       "537   0.962963  0.100775   0.944107\n",
       "538   0.961538  0.096899   0.945314\n",
       "539   0.960000  0.093023   0.950588\n",
       "540   0.958333  0.089147   0.950926\n",
       "541   0.956522  0.085271   0.951095\n",
       "542   0.954545  0.081395   0.951633\n",
       "543   0.952381  0.077519   0.953706\n",
       "544   0.950000  0.073643   0.953800\n",
       "545   0.947368  0.069767   0.954572\n",
       "546   0.944444  0.065891   0.955712\n",
       "547   0.941176  0.062016   0.956683\n",
       "548   0.937500  0.058140   0.957002\n",
       "549   0.933333  0.054264   0.957779\n",
       "550   0.928571  0.050388   0.958622\n",
       "551   0.923077  0.046512   0.959153\n",
       "552   0.916667  0.042636   0.961715\n",
       "553   0.909091  0.038760   0.963038\n",
       "554   0.900000  0.034884   0.964177\n",
       "555   0.888889  0.031008   0.964340\n",
       "556   0.875000  0.027132   0.964521\n",
       "557   0.857143  0.023256   0.965484\n",
       "558   0.800000  0.015504   0.965561\n",
       "559   0.750000  0.011628   0.969996\n",
       "560   0.666667  0.007752   0.970968\n",
       "561   1.000000  0.007752   0.973211\n",
       "562   1.000000  0.003876   0.974678"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the last 50 combinations of precision-recall-threshold\n",
    "prt_df.tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bbb7e667137b1b41e220ce0fb3ed79b49f3e22f0"
   },
   "source": [
    "If we now select survivors based on the new probability threshold, we finally obtain a nonzero number of survivors. In this particular case 13 people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "8926fcd98b06ba0b9af3b68579889a28bd6b5217"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the number of predicted survivors using the new threshold\n",
    "y_proba_test = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_proba_test >= 0.932465).astype(int)\n",
    "np.count_nonzero(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "766d9d59846a62ef1003eab10c99b7825adeb930"
   },
   "source": [
    "Furthermore, we can check how well the target variables correspond with our predictions. It turns out that there is a perfect match (precision of 1.0) and it is even better than the precision that we aimed on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "37d25a9a18ecadd3ef75668902cba6db53399aff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.94751319],\n",
       "       [1.        , 0.93842582],\n",
       "       [1.        , 0.96626347],\n",
       "       [1.        , 0.95822958],\n",
       "       [1.        , 0.95844455],\n",
       "       [1.        , 0.95454875],\n",
       "       [1.        , 0.95465325],\n",
       "       [1.        , 0.94716191],\n",
       "       [1.        , 0.94935889],\n",
       "       [1.        , 0.97058184],\n",
       "       [1.        , 0.94185192],\n",
       "       [1.        , 0.95991282],\n",
       "       [1.        , 0.95343004]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pairs of target labels and predicted probabilities above the new threshold\n",
    "yy = np.array(list(zip(y_test, y_proba_test)))\n",
    "indices = np.where(yy[:,1] >= 0.932465)\n",
    "yy[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2225e21b3051048f122946a202c209f933b6fbe2"
   },
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "Let's compare what we had before and after the threshold adjustment.\n",
    "\n",
    "* *Before*: 61 correctly predicted survivors, 23 wrongly predicted survivors, precision 0.73.\n",
    "* *After*: 13 correctly predicted survivors, 0 wrongly predicted survivors, precision 1.0.\n",
    "\n",
    "So in the end we managed to decrease the number of insurance claims down to 0 and at the same time sold insurances to 13 people. This is also confirmed by the precision score that has increased from 0.73 up to 1.0.\n",
    "\n",
    "---\n",
    "Thanks for **UPVOTING** this kernel! Trying to become a Kernel Expert. 👍\n",
    "\n",
    "> Check out other interesting projects related to Titanic by Pavlo Fesenko:\n",
    "- [(kernel) How to extend Titanic dataset using Wikipedia?](https://www.kaggle.com/pavlofesenko/extending-titanic-dataset-using-wikipedia)\n",
    "- [(dataset) Titanic extended (Kaggle + Wikipedia)](https://www.kaggle.com/pavlofesenko/titanic-extended)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
